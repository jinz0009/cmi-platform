# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from sqlalchemy import create_engine, text
import hashlib, io, re, math
from datetime import date

# ============ åŸºç¡€é…ç½® ============
st.set_page_config(page_title="CMI è¯¢ä»·å½•å…¥ä¸æŸ¥è¯¢å¹³å°", layout="wide")

# ä½¿ç”¨æœ¬åœ° SQLiteï¼ˆä¸´æ—¶å­˜å‚¨ï¼‰
engine = create_engine("sqlite:///quotation.db")

# ============ åˆå§‹åŒ–æ•°æ®åº“ ============
with engine.begin() as conn:
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT UNIQUE,
        password TEXT,
        role TEXT CHECK(role IN ('admin','user')),
        region TEXT
    )
    """))
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS quotations (
        åºå· TEXT,
        è®¾å¤‡ææ–™åç§° TEXT NOT NULL,
        è§„æ ¼æˆ–å‹å· TEXT,
        æè¿° TEXT,
        å“ç‰Œ TEXT NOT NULL,
        å•ä½ TEXT,
        æ•°é‡ç¡®è®¤ REAL,
        æŠ¥ä»·å“ç‰Œ TEXT,
        å‹å· TEXT,
        è®¾å¤‡å•ä»· REAL,
        è®¾å¤‡å°è®¡ REAL,
        äººå·¥åŒ…å¹²å•ä»· REAL,
        äººå·¥åŒ…å¹²å°è®¡ REAL,
        ç»¼åˆå•ä»·æ±‡æ€» REAL,
        å¸ç§ TEXT,
        åŸå‚å“ç‰Œç»´ä¿æœŸé™ TEXT,
        è´§æœŸ TEXT,
        å¤‡æ³¨ TEXT,
        è¯¢ä»·äºº TEXT,
        é¡¹ç›®åç§° TEXT,
        ä¾›åº”å•†åç§° TEXT,
        è¯¢ä»·æ—¥æœŸ TEXT,
        å½•å…¥äºº TEXT,
        åœ°åŒº TEXT
    )
    """))
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS misc_costs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        é¡¹ç›®åç§° TEXT,
        æ‚è´¹ç±»ç›® TEXT,
        é‡‘é¢ REAL,
        å¸ç§ TEXT,
        å½•å…¥äºº TEXT,
        åœ°åŒº TEXT
    )
    """))
    conn.execute(text("""
    INSERT OR IGNORE INTO users (username, password, role, region)
    VALUES ('admin', :pw, 'admin', 'All')
    """), {"pw": hashlib.sha256("admin123".encode()).hexdigest()})

# ============ è¡¨å¤´æ˜ å°„å­—å…¸ï¼ˆå¯æ‰©å±•ï¼‰ ============
HEADER_SYNONYMS = {
    "åºå·": "åºå·", "no": "åºå·", "index": "åºå·",
    "è®¾å¤‡ææ–™åç§°": "è®¾å¤‡ææ–™åç§°", "è®¾å¤‡åç§°": "è®¾å¤‡ææ–™åç§°",
    "material": "è®¾å¤‡ææ–™åç§°", "material name": "è®¾å¤‡ææ–™åç§°",
    "item": "è®¾å¤‡ææ–™åç§°", "name": "è®¾å¤‡ææ–™åç§°",
    "è§„æ ¼æˆ–å‹å·": "è§„æ ¼æˆ–å‹å·", "è§„æ ¼": "è§„æ ¼æˆ–å‹å·", "model": "è§„æ ¼æˆ–å‹å·", "spec": "è§„æ ¼æˆ–å‹å·",
    "æè¿°": "æè¿°", "description": "æè¿°",
    "å“ç‰Œ": "å“ç‰Œ", "brand": "å“ç‰Œ",
    "å•ä½": "å•ä½", "unit": "å•ä½",
    "æ•°é‡ç¡®è®¤": "æ•°é‡ç¡®è®¤", "æ•°é‡": "æ•°é‡ç¡®è®¤", "qty": "æ•°é‡ç¡®è®¤", "quantity": "æ•°é‡ç¡®è®¤",
    "æŠ¥ä»·å“ç‰Œ": "æŠ¥ä»·å“ç‰Œ", "æŠ¥ä»·": "æŠ¥ä»·å“ç‰Œ",
    "å‹å·": "å‹å·",
    "è®¾å¤‡å•ä»·": "è®¾å¤‡å•ä»·", "å•ä»·": "è®¾å¤‡å•ä»·", "price": "è®¾å¤‡å•ä»·", "unit price": "è®¾å¤‡å•ä»·",
    "è®¾å¤‡å°è®¡": "è®¾å¤‡å°è®¡", "subtotal": "è®¾å¤‡å°è®¡",
    "äººå·¥åŒ…å¹²å•ä»·": "äººå·¥åŒ…å¹²å•ä»·", "äººå·¥åŒ…å¹²å°è®¡": "äººå·¥åŒ…å¹²å°è®¡", "ç»¼åˆå•ä»·æ±‡æ€»": "ç»¼åˆå•ä»·æ±‡æ€»",
    "å¸ç§": "å¸ç§", "currency": "å¸ç§",
    "åŸå‚å“ç‰Œç»´ä¿æœŸé™": "åŸå‚å“ç‰Œç»´ä¿æœŸé™", "è´§æœŸ": "è´§æœŸ",
    "å¤‡æ³¨": "å¤‡æ³¨", "remark": "å¤‡æ³¨", "notes": "å¤‡æ³¨",
    "è¯¢ä»·äºº": "è¯¢ä»·äºº", "enquirer": "è¯¢ä»·äºº", "inquirer": "è¯¢ä»·äºº",
    "é¡¹ç›®åç§°": "é¡¹ç›®åç§°", "project": "é¡¹ç›®åç§°", "project name": "é¡¹ç›®åç§°",
    "ä¾›åº”å•†åç§°": "ä¾›åº”å•†åç§°", "supplier": "ä¾›åº”å•†åç§°", "vendor": "ä¾›åº”å•†åç§°",
    "è¯¢ä»·æ—¥æœŸ": "è¯¢ä»·æ—¥æœŸ", "date": "è¯¢ä»·æ—¥æœŸ",
    "å½•å…¥äºº": "å½•å…¥äºº", "åœ°åŒº": "åœ°åŒº",
    # å¸¸è§å¸¦æ‹¬å·/å¸ç§å†™æ³•
    "è®¾å¤‡å•ä»·ï¼ˆidrï¼‰": "è®¾å¤‡å•ä»·", "è®¾å¤‡å•ä»·(idr)": "è®¾å¤‡å•ä»·", "è®¾å¤‡å•ä»·ï¼ˆrmbï¼‰": "è®¾å¤‡å•ä»·",
    "è®¾å¤‡å•ä»·(rmb)": "è®¾å¤‡å•ä»·", "è®¾å¤‡å°è®¡ï¼ˆidrï¼‰": "è®¾å¤‡å°è®¡", "è®¾å¤‡å°è®¡(idr)": "è®¾å¤‡å°è®¡",
    "è®¾å¤‡å°è®¡ï¼ˆrmbï¼‰": "è®¾å¤‡å°è®¡", "è®¾å¤‡å°è®¡(rmb)": "è®¾å¤‡å°è®¡",
    "äººå·¥åŒ…å¹²å•ä»·ï¼ˆidrï¼‰": "äººå·¥åŒ…å¹²å•ä»·", "äººå·¥åŒ…å¹²å•ä»·(idr)": "äººå·¥åŒ…å¹²å•ä»·",
    "äººå·¥åŒ…å¹²å°è®¡ï¼ˆidrï¼‰": "äººå·¥åŒ…å¹²å°è®¡", "äººå·¥åŒ…å¹²å°è®¡(idr)": "äººå·¥åŒ…å¹²å°è®¡",
    "ç»¼åˆå•ä»·æ±‡æ€»ï¼ˆidrï¼‰": "ç»¼åˆå•ä»·æ±‡æ€»", "ç»¼åˆå•ä»·æ±‡æ€»(idr)": "ç»¼åˆå•ä»·æ±‡æ€»",
    "price (idr)": "è®¾å¤‡å•ä»·", "subtotal (idr)": "è®¾å¤‡å°è®¡",
}

# æ•°æ®åº“åˆ—é¡ºåº
DB_COLUMNS = [
    "åºå·","è®¾å¤‡ææ–™åç§°","è§„æ ¼æˆ–å‹å·","æè¿°","å“ç‰Œ","å•ä½","æ•°é‡ç¡®è®¤",
    "æŠ¥ä»·å“ç‰Œ","å‹å·","è®¾å¤‡å•ä»·","è®¾å¤‡å°è®¡","äººå·¥åŒ…å¹²å•ä»·","äººå·¥åŒ…å¹²å°è®¡",
    "ç»¼åˆå•ä»·æ±‡æ€»","å¸ç§","åŸå‚å“ç‰Œç»´ä¿æœŸé™","è´§æœŸ","å¤‡æ³¨",
    "è¯¢ä»·äºº","é¡¹ç›®åç§°","ä¾›åº”å•†åç§°","è¯¢ä»·æ—¥æœŸ","å½•å…¥äºº","åœ°åŒº"
]

# helper: è‡ªåŠ¨æ˜ å°„è¡¨å¤´
def auto_map_header(orig_header: str):
    if orig_header is None:
        return None
    h = str(orig_header).strip().lower()
    for k, v in HEADER_SYNONYMS.items():
        if h == k.lower():
            return v
    h_norm = re.sub(r"[\s\-\_ï¼š:ï¼ˆï¼‰()]+", " ", h).strip()
    for k, v in HEADER_SYNONYMS.items():
        k_norm = re.sub(r"[\s\-\_ï¼š:ï¼ˆï¼‰()]+", " ", k.lower()).strip()
        if h_norm == k_norm:
            return v
    for k, v in HEADER_SYNONYMS.items():
        if k.lower() in h or h in k.lower():
            return v
    words = re.findall(r"[a-zA-Z\u4e00-\u9fff]+", h)
    for w in words:
        for k, v in HEADER_SYNONYMS.items():
            if w == k.lower():
                return v
    return None

# å°è¯•ä»é¢„è§ˆæ£€æµ‹è¡¨å¤´ï¼ˆæ”¯æŒå•/åŒè¡Œï¼‰
def detect_header_from_preview(df_preview: pd.DataFrame, max_header_rows=2, max_search_rows=8):
    nrows = df_preview.shape[0]
    ncols = df_preview.shape[1]
    search_rows = min(max_search_rows, nrows)
    best = {"score": -1, "header": None, "row": None, "rows_used": 1}
    for start in range(search_rows):
        for rows_used in range(1, max_header_rows + 1):
            if start + rows_used > nrows:
                continue
            cand = []
            for col in range(ncols):
                parts = []
                for r in range(start, start + rows_used):
                    cell = df_preview.iat[r, col]
                    if pd.isna(cell):
                        continue
                    s = str(cell).strip()
                    if s:
                        parts.append(s)
                header_text = " ".join(parts).strip()
                cand.append(header_text)
            mapped_count = 0
            nonempty_count = sum(1 for x in cand if x)
            for h in cand:
                if h and auto_map_header(h):
                    mapped_count += 1
            score = mapped_count + 0.5 * nonempty_count
            if score > best["score"]:
                best = {"score": score, "header": cand, "row": start, "rows_used": rows_used, "mapped": mapped_count, "nonempty": nonempty_count}
    if best["header"] is not None:
        if best["mapped"] >= 2 or (best["nonempty"] > 0 and best["mapped"] / best["nonempty"] >= 0.3):
            return best["header"], best["row"] + best["rows_used"] - 1
    return None, None

# ============ å®‰å…¨æ˜¾ç¤ºï¼ˆè§„èŒƒåŒ–ç”¨äºæ˜¾ç¤ºä»¥é¿å… Arrow é”™è¯¯ï¼‰ ============
def normalize_for_display(df: pd.DataFrame) -> pd.DataFrame:
    df_disp = df.copy()
    for col in df_disp.columns:
        try:
            ser = df_disp[col]
            if ser.dtype != "object":
                continue
            non_null = ser.dropna()
            if non_null.empty:
                df_disp[col] = ser.where(ser.notna(), "").astype(str)
                continue
            has_bytes = any(isinstance(x, (bytes, bytearray, memoryview)) for x in non_null)
            types_seen = {type(x) for x in non_null}
            multiple_types = len(types_seen) > 1
            if has_bytes or multiple_types:
                df_disp[col] = ser.where(ser.notna(), None).apply(lambda x: "" if x is None else str(x))
            else:
                df_disp[col] = ser.where(ser.notna(), None).apply(lambda x: "" if x is None else x)
        except Exception:
            df_disp[col] = df_disp[col].where(df_disp[col].notna(), None).apply(lambda x: "" if x is None else str(x))
    return df_disp

def safe_st_dataframe(df: pd.DataFrame, height: int | None = None):
    df_disp = normalize_for_display(df)
    try:
        if height is None:
            st.dataframe(df_disp)
        else:
            st.dataframe(df_disp, height=height)
    except Exception:
        df2 = df_disp.copy()
        for col in df2.columns:
            try:
                df2[col] = df2[col].where(df2[col].notna(), None).apply(lambda x: "" if x is None else str(x))
            except Exception:
                df2[col] = df2[col].astype(str).fillna("")
        if height is None:
            st.dataframe(df2)
        else:
            st.dataframe(df2, height=height)

# ============ ç™»å½•æ³¨å†Œé€»è¾‘ ============
def login():
    st.subheader("ğŸ” ç”¨æˆ·ç™»å½•")
    username = st.text_input("ç”¨æˆ·å")
    password = st.text_input("å¯†ç ", type="password")
    if st.button("ç™»å½•"):
        pw_hash = hashlib.sha256(password.encode()).hexdigest()
        with engine.begin() as conn:
            user = conn.execute(
                text("SELECT * FROM users WHERE username=:u AND password=:p"),
                {"u": username, "p": pw_hash}
            ).fetchone()
        if user:
            st.session_state["user"] = {"username": username, "role": user.role, "region": user.region}
            st.success(f"âœ… ç™»å½•æˆåŠŸï¼æ¬¢è¿ {username}ï¼ˆ{user.region}ï¼‰")
            st.rerun()
        else:
            st.error("âŒ ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

def register():
    st.subheader("ğŸ§¾ æ³¨å†Œæ–°ç”¨æˆ·")
    username = st.text_input("æ–°ç”¨æˆ·å")
    password = st.text_input("æ–°å¯†ç ", type="password")
    region = st.selectbox("æ‰€å±åœ°åŒº", ["Singapore","Malaysia","Thailand","Indonesia","Vietnam","Philippines","Others"])
    if st.button("æ³¨å†Œ"):
        if not username or not password:
            st.warning("è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ")
        else:
            pw_hash = hashlib.sha256(password.encode()).hexdigest()
            try:
                with engine.begin() as conn:
                    conn.execute(
                        text("INSERT INTO users (username, password, role, region) VALUES (:u, :p, 'user', :r)"),
                        {"u": username, "p": pw_hash, "r": region}
                    )
                st.success("âœ… æ³¨å†ŒæˆåŠŸï¼Œè¯·è¿”å›ç™»å½•é¡µã€‚")
            except Exception:
                st.error("âŒ ç”¨æˆ·åå·²å­˜åœ¨")

def logout():
    st.session_state.clear()
    st.rerun()

# ============ é¡µé¢åˆ‡æ¢ ============
if "user" not in st.session_state:
    tab = st.tabs(["ğŸ”‘ ç™»å½•", "ğŸ§¾ æ³¨å†Œ"])
    with tab[0]:
        login()
    with tab[1]:
        register()
    st.stop()

user = st.session_state["user"]
st.sidebar.markdown(f"ğŸ‘¤ **{user['username']}**  \nğŸ¢ åœ°åŒºï¼š{user['region']}  \nğŸ”‘ è§’è‰²ï¼š{user['role']}")
if st.sidebar.button("ğŸšª é€€å‡ºç™»å½•"):
    logout()

page = st.sidebar.radio("å¯¼èˆª", ["ğŸ  ä¸»é¡µé¢", "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢", "ğŸ’° æ‚è´¹æŸ¥è¯¢", "ğŸ‘‘ ç®¡ç†å‘˜åå°"] if user["role"]=="admin" else ["ğŸ  ä¸»é¡µé¢", "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢", "ğŸ’° æ‚è´¹æŸ¥è¯¢"])

# ============ ä¸»é¡µé¢ï¼šå½•å…¥ ============
if page == "ğŸ  ä¸»é¡µé¢":
    st.title("ğŸ“Š è¯¢ä»·å½•å…¥ä¸æŸ¥è¯¢å¹³å°")

    st.header("ğŸ“‚ Excel æ‰¹é‡å½•å…¥ï¼ˆæ™ºèƒ½è¡¨å¤´æ˜ å°„ï¼‰")
    st.caption("ç³»ç»Ÿä¼šå°è¯•è¯†åˆ«ä¸Šä¼ æ–‡ä»¶çš„è¡¨å¤´ï¼ˆæ”¯æŒå‰å‡ è¡Œä¸ºåˆå¹¶å•å…ƒæ ¼æˆ–æ ‡é¢˜ï¼‰ï¼Œå¹¶ç»™å‡ºå»ºè®®æ˜ å°„ã€‚ç³»ç»Ÿä¼šå…ˆè‡ªåŠ¨å¯¹åº”ä¸€ç‰ˆå»ºè®®ï¼Œä½ å¯ä»¥æŒ‰åˆ—ä¿®æ”¹å¹¶çœ‹åˆ°å“ªäº›ç›®æ ‡åˆ—æœªè¢«æä¾›æˆ–æ— å€¼ã€‚")

    template = pd.DataFrame(columns=[c for c in DB_COLUMNS if c not in ("å½•å…¥äºº","åœ°åŒº")])
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as w:
        template.to_excel(w, index=False)
    buf.seek(0)
    st.download_button("ğŸ“¥ ä¸‹è½½æ¨¡æ¿", buf, "quotation_template.xlsx")

    uploaded = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶ï¼ˆ.xlsxï¼‰", type=["xlsx"])
    if uploaded:
        # åˆå§‹åŒ–ä¼šè¯å˜é‡ï¼ˆé¿å… KeyErrorï¼‰
        if "mapping_done" not in st.session_state:
            st.session_state["mapping_done"] = False
        if "bulk_applied" not in st.session_state:
            st.session_state["bulk_applied"] = False

        try:
            preview = pd.read_excel(uploaded, header=None, nrows=50, dtype=object)
        except Exception as e:
            st.error(f"è¯»å– Excel é¢„è§ˆå¤±è´¥ï¼š{e}")
            preview = None

        if preview is not None:
            st.markdown("**ç”¨äºè¯†åˆ«è¡¨å¤´çš„å‰å‡ è¡Œé¢„è§ˆï¼ˆä»…å±•ç¤ºï¼‰ï¼š**")
            safe_st_dataframe(preview.head(10))

            header_names, header_row_index = detect_header_from_preview(preview, max_header_rows=2, max_search_rows=8)
            raw_df_full = pd.read_excel(uploaded, header=None, dtype=object)

            if header_names is None:
                st.info("æœªèƒ½è‡ªåŠ¨è¯†åˆ«è¡¨å¤´ï¼Œè¯·æ‰‹åŠ¨æ˜ å°„ï¼ˆç³»ç»Ÿå·²æŠŠç¬¬ä¸€è¡Œä½œä¸ºå€™é€‰ï¼‰ã€‚")
                header_row_index = 0
                header_names = [str(x) if not pd.isna(x) else "" for x in raw_df_full.iloc[0].tolist()]
            else:
                st.success(f"å·²æ£€æµ‹åˆ°è¡¨å¤´ï¼ˆç»“æŸäºç¬¬ {header_row_index+1} è¡Œï¼‰ï¼Œç³»ç»Ÿå·²ç”Ÿæˆå»ºè®®æ˜ å°„ï¼š")
                st.write(header_names)

            header_names = [str(x).strip() if (x is not None and not pd.isna(x)) else "" for x in header_names]

            data_df = raw_df_full.iloc[header_row_index+1 : ].copy().reset_index(drop=True)
            if len(header_names) < data_df.shape[1]:
                header_names += [f"Unnamed_{i}" for i in range(len(header_names), data_df.shape[1])]
            elif len(header_names) > data_df.shape[1]:
                header_names = header_names[:data_df.shape[1]]

            data_df.columns = header_names

            st.markdown("**æ£€æµ‹åˆ°çš„åŸå§‹è¡¨å¤´ï¼ˆç”¨äºæ˜ å°„ï¼Œç³»ç»Ÿå·²å°è¯•è‡ªåŠ¨å¯¹åº”ä¸€ç‰ˆå»ºè®®ï¼‰ï¼š**")
            st.write(list(data_df.columns))

            # å¦‚æœä¼šè¯ä¸­å·²æœ‰ mapping_doneï¼Œåˆ™ä¼˜å…ˆä»ä¼šè¯æ¢å¤æ˜ å°„ç»“æœï¼ˆé¿å…å¾ªç¯ï¼‰
            if st.session_state.get("mapping_done", False) and st.session_state.get("mapping_csv", None):
                try:
                    csv_buf = io.StringIO(st.session_state["mapping_csv"])
                    df_for_db = pd.read_csv(csv_buf, dtype=object)
                    # ç¡®ä¿åˆ—å®Œæ•´
                    for c in DB_COLUMNS:
                        if c not in df_for_db.columns:
                            df_for_db[c] = pd.NA
                    df_for_db = df_for_db[DB_COLUMNS]
                    st.info("å·²ä»ä¼šè¯æ¢å¤ä¸Šæ¬¡æ˜ å°„ç»“æœã€‚è‹¥è¦é‡æ–°æ˜ å°„ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹â€œæ¸…é™¤æ˜ å°„å¹¶é‡æ–°æ˜ å°„â€ã€‚")
                    if st.button("æ¸…é™¤æ˜ å°„å¹¶é‡æ–°æ˜ å°„"):
                        for k in ["mapping_done","mapping_csv","mapping_rename_dict","mapping_target_sources","mapping_mapped_but_empty","bulk_applied","bulk_values"]:
                            if k in st.session_state:
                                del st.session_state[k]
                        st.experimental_rerun()
                    safe_st_dataframe(df_for_db.head(10))
                    st.write("è‹¥éœ€è¦ä¿®æ”¹æ˜ å°„ï¼Œè¯·å…ˆç‚¹å‡»æ¸…é™¤æ˜ å°„å¹¶é‡æ–°æ‰§è¡Œæ˜ å°„æµç¨‹ã€‚")
                except Exception:
                    st.warning("ä¼šè¯æ¢å¤ä¸Šæ¬¡æ˜ å°„å¤±è´¥ï¼Œè¯·é‡æ–°æ‰§è¡Œæ˜ å°„ã€‚")
                    for k in ["mapping_done","mapping_csv","mapping_rename_dict","mapping_target_sources","mapping_mapped_but_empty"]:
                        if k in st.session_state:
                            del st.session_state[k]

            # æ„å»ºæ˜ å°„ä¸‹æ‹‰é€‰é¡¹
            mapping_targets = ["Ignore"] + [c for c in DB_COLUMNS if c not in ("å½•å…¥äºº","åœ°åŒº")]

            # è‡ªåŠ¨å»ºè®®
            auto_defaults = {}
            for col in data_df.columns:
                auto_val = auto_map_header(col)
                if auto_val and auto_val in mapping_targets:
                    auto_defaults[col] = auto_val
                else:
                    auto_defaults[col] = "Ignore"

            st.markdown("ç³»ç»Ÿå·²ä¸ºæ¯ä¸€åˆ—ç”Ÿæˆå»ºè®®æ˜ å°„ï¼ˆä½ å¯ä»¥ç›´æ¥ç‚¹å‡»â€œåº”ç”¨æ˜ å°„å¹¶é¢„è§ˆâ€ æˆ– ä¿®æ”¹ä»»æ„ä¸‹æ‹‰å†æäº¤ï¼‰ã€‚")

            mapped_choices = {}
            with st.form("mapping_form"):
                cols_left, cols_right = st.columns(2)
                for i, col in enumerate(data_df.columns):
                    default = auto_defaults.get(col, "Ignore")
                    container = cols_left if i % 2 == 0 else cols_right
                    sel = container.selectbox(f"æºåˆ—: {col}", mapping_targets,
                                              index = mapping_targets.index(default) if default in mapping_targets else 0,
                                              key=f"map_{i}")
                    mapped_choices[col] = sel
                submitted = st.form_submit_button("åº”ç”¨æ˜ å°„å¹¶é¢„è§ˆ")

            # mapping_form æäº¤åï¼šæŒä¹…åŒ–æ˜ å°„ç»“æœåˆ° session_stateï¼Œé¿å…åç»­ rerun ä¸¢å¤±
            if submitted:
                target_sources = {}
                for src, tgt in mapped_choices.items():
                    if tgt != "Ignore":
                        target_sources.setdefault(tgt, []).append(src)

                # é‡å¤æ˜ å°„æ£€æµ‹ -> é˜»æ­¢å¹¶æç¤º
                dup_targets = {t: s for t, s in target_sources.items() if len(s) > 1}
                if dup_targets:
                    dup_messages = []
                    for t, srcs in dup_targets.items():
                        dup_messages.append(f"ç›®æ ‡åˆ— '{t}' è¢«å¤šä¸ªæºåˆ—æ˜ å°„: {', '.join(srcs)}")
                    st.error("æ£€æµ‹åˆ°å¤šä¸ªæºåˆ—æ˜ å°„åŒä¸€ç›®æ ‡åˆ—ï¼ˆè¿™æ˜¯ä¸å…è®¸çš„ï¼‰ã€‚è¯·ä¿®æ­£æ˜ å°„åå†ç»§ç»­ã€‚\n\n" + "\n".join(dup_messages))
                else:
                    # æ£€æµ‹è¢«æ˜ å°„ä½†æºåˆ—å…¨ç©º
                    mapped_but_empty = []
                    for tgt, srcs in target_sources.items():
                        has_value = False
                        for s in srcs:
                            if s in data_df.columns:
                                col_series = data_df[s].astype(object).where(~data_df[s].astype(str).str.strip().isin(["", "nan", "none"]), pd.NA)
                                if col_series.dropna().size > 0:
                                    has_value = True
                                    break
                        if not has_value:
                            mapped_but_empty.append(tgt)

                    rename_dict = {orig: mapped for orig, mapped in mapped_choices.items() if mapped != "Ignore"}
                    df_mapped = data_df.rename(columns=rename_dict).copy()
                    for c in DB_COLUMNS:
                        if c not in df_mapped.columns:
                            df_mapped[c] = pd.NA
                    df_mapped["å½•å…¥äºº"] = user["username"]
                    df_mapped["åœ°åŒº"] = user["region"]
                    df_for_db = df_mapped[DB_COLUMNS]

                    # æŠŠ df_for_db åºåˆ—åŒ–ä¸º CSV å­˜å…¥ session_state ä»¥ä¾¿è·¨ rerun æ¢å¤
                    csv_buf = io.StringIO()
                    df_for_db.to_csv(csv_buf, index=False)
                    st.session_state["mapping_csv"] = csv_buf.getvalue()
                    st.session_state["mapping_done"] = True
                    st.session_state["mapping_rename_dict"] = rename_dict
                    st.session_state["mapping_target_sources"] = target_sources
                    st.session_state["mapping_mapped_but_empty"] = mapped_but_empty

                    st.success("æ˜ å°„å·²ä¿å­˜ã€‚ç°åœ¨è¯·å¡«å†™å…¨å±€å¿…å¡«ä¿¡æ¯å¹¶æäº¤ä»¥ç»§ç»­æ ¡éªŒä¸å¯¼å…¥ã€‚")
                    # ä¸ä½¿ç”¨ st.stop()ï¼Œè®©é¡µé¢åœ¨ rerun ååŸºäº session_state ç»§ç»­

            # å¦‚æœä¼šè¯ä¸­å·²æœ‰æ˜ å°„å¹¶æ¢å¤ df_for_dbï¼Œä¸Šé¢å·²ç»æ˜¾ç¤ºé¢„è§ˆå¹¶æä¾›æ¸…é™¤æŒ‰é’®
            # ä¸‹é¢ä»ç„¶æä¾› global_formï¼ˆå¦‚æœ mapping_done ä¸º True æˆ–è€…åˆšåˆš submittedï¼‰
            mapping_available = st.session_state.get("mapping_done", False) or ('df_for_db' in locals())

            if mapping_available:
                # å°è¯•ä» session_state æ¢å¤ df_for_dbï¼ˆä¼˜å…ˆï¼‰
                if st.session_state.get("mapping_done", False) and st.session_state.get("mapping_csv", None):
                    csv_buf = io.StringIO(st.session_state["mapping_csv"])
                    df_for_db = pd.read_csv(csv_buf, dtype=object)
                    for c in DB_COLUMNS:
                        if c not in df_for_db.columns:
                            df_for_db[c] = pd.NA
                    df_for_db = df_for_db[DB_COLUMNS]

                st.markdown("**æ˜ å°„åé¢„è§ˆï¼ˆå‰ 10 è¡Œï¼‰ï¼š**")
                safe_st_dataframe(df_for_db.head(10))

                # ========== åŠ¨æ€å†³å®šæ˜¯å¦æŠŠ å¸ç§ è®¾ä¸ºå…¨å±€å¿…å¡« ==========
                def column_has_empty_currency(df: pd.DataFrame) -> bool:
                    if "å¸ç§" not in df.columns:
                        return True
                    ser = df["å¸ç§"]
                    def is_empty_val(x):
                        if pd.isna(x):
                            return True
                        s = str(x).strip().lower()
                        return s == "" or s in ("nan", "none")
                    return any(is_empty_val(x) for x in ser)

                need_global_currency = column_has_empty_currency(df_for_db)

                # global_form: é€šè¿‡ session_state æ§åˆ¶å·²æäº¤çŠ¶æ€ï¼ˆé¿å…å±€éƒ¨å˜é‡åœ¨ rerun ä¸­ä¸¢å¤±ï¼‰
                if "bulk_values" not in st.session_state:
                    st.session_state["bulk_values"] = {"project": "", "supplier": "", "enquirer": "", "date": "", "currency": ""}

                st.markdown("è¯·å¡«å†™å…¨å±€å¿…å¡«ä¿¡æ¯ï¼ˆä¼šåº”ç”¨åˆ°æ‰€æœ‰å¯¼å…¥è®°å½•ï¼‰ï¼Œå¡«å†™å®Œåç‚¹å‡»â€œåº”ç”¨å…¨å±€å¹¶ç»§ç»­æ ¡éªŒâ€ï¼š")
                # å¸ƒå±€ï¼š5 åˆ—ï¼ˆå¦‚æœä¸éœ€è¦å¸ç§ï¼Œç¬¬5åˆ—ç•™ç©ºï¼‰
                with st.form("global_form"):
                    col_a, col_b, col_c, col_d, col_e = st.columns(5)
                    g_project = col_a.text_input("é¡¹ç›®åç§°", key="bulk_project_input", value=st.session_state["bulk_values"].get("project", ""))
                    g_supplier = col_b.text_input("ä¾›åº”å•†åç§°", key="bulk_supplier_input", value=st.session_state["bulk_values"].get("supplier", ""))
                    g_enquirer = col_c.text_input("è¯¢ä»·äºº", key="bulk_enquirer_input", value=st.session_state["bulk_values"].get("enquirer", ""))
                    default_date = st.session_state["bulk_values"].get("date", "")
                    try:
                        if default_date:
                            g_date = col_d.date_input("è¯¢ä»·æ—¥æœŸ", value=pd.to_datetime(default_date).date(), key="bulk_date_input")
                        else:
                            g_date = col_d.date_input("è¯¢ä»·æ—¥æœŸ", value=date.today(), key="bulk_date_input")
                    except Exception:
                        g_date = col_d.date_input("è¯¢ä»·æ—¥æœŸ", value=date.today(), key="bulk_date_input")

                    g_currency = None
                    if need_global_currency:
                        currency_options = ["IDR", "USD", "RMB", "SGD", "MYR", "THB"]
                        curr_default = st.session_state["bulk_values"].get("currency", "")
                        if curr_default and curr_default in currency_options:
                            default_idx = currency_options.index(curr_default)
                        else:
                            default_idx = 0
                        g_currency = col_e.selectbox("å¸ç§ï¼ˆå¿…å¡«ï¼Œå› æºæ•°æ®ç¼ºå¤±ï¼‰", currency_options, index=default_idx, key="bulk_currency_input")
                    else:
                        col_e.write("")  # ä¿æŒå¸ƒå±€
                    apply_global = st.form_submit_button("åº”ç”¨å…¨å±€å¹¶ç»§ç»­æ ¡éªŒ")

                # æŒ‰é’®æŒ‰ä¸‹åä¿å­˜åˆ° session_stateï¼ˆå¹¶æ ¡éªŒå¸ç§æ˜¯å¦å¿…å¡«ï¼‰
                if apply_global:
                    if not (g_project and g_supplier and g_enquirer and g_date):
                        st.error("å¿…é¡»å¡«å†™ï¼šé¡¹ç›®åç§°ã€ä¾›åº”å•†åç§°ã€è¯¢ä»·äººå’Œè¯¢ä»·æ—¥æœŸï¼Œæ‰èƒ½ç»§ç»­å¯¼å…¥ã€‚")
                        st.session_state["bulk_applied"] = False
                    elif need_global_currency and (g_currency is None or str(g_currency).strip() == ""):
                        st.error("ç”±äºæºæ•°æ®ä¸­å­˜åœ¨ç©ºçš„å¸ç§ï¼Œå¸ç§å·²è¢«è®¾ä¸ºå…¨å±€å¿…å¡«ï¼Œè¯·é€‰æ‹©å¸ç§åç»§ç»­ã€‚")
                        st.session_state["bulk_applied"] = False
                    else:
                        st.session_state["bulk_applied"] = True
                        st.session_state["bulk_values"] = {
                            "project": str(g_project),
                            "supplier": str(g_supplier),
                            "enquirer": str(g_enquirer),
                            "date": str(g_date),
                            "currency": str(g_currency) if g_currency is not None else st.session_state["bulk_values"].get("currency", "")
                        }
                        st.success("å·²åº”ç”¨å…¨å±€ä¿¡æ¯ï¼Œæ­£åœ¨è¿›è¡Œæ€»ä½“å¿…å¡«æ ¡éªŒ...")

                # å¦‚æœå°šæœªåº”ç”¨å…¨å±€ï¼Œæç¤ºç”¨æˆ·
                if not st.session_state.get("bulk_applied", False):
                    st.info("è¯·å¡«å†™å…¨å±€å¿…å¡«ä¿¡æ¯å¹¶ç‚¹å‡»â€œåº”ç”¨å…¨å±€å¹¶ç»§ç»­æ ¡éªŒâ€ä»¥ç»§ç»­ã€‚")
                else:
                    # è¯»å– df_for_dbï¼ˆä¼˜å…ˆä» session_stateï¼‰
                    if st.session_state.get("mapping_done", False) and st.session_state.get("mapping_csv", None):
                        csv_buf = io.StringIO(st.session_state["mapping_csv"])
                        df_for_db = pd.read_csv(csv_buf, dtype=object)
                        for c in DB_COLUMNS:
                            if c not in df_for_db.columns:
                                df_for_db[c] = pd.NA
                        df_for_db = df_for_db[DB_COLUMNS]

                    # æ„å»º df_finalï¼šæŠŠå…¨å±€å­—æ®µåº”ç”¨åˆ°æ‰€æœ‰è¡Œï¼ˆè¦†ç›–ï¼‰
                    df_final = df_for_db.copy()
                    g = st.session_state["bulk_values"]
                    df_final["é¡¹ç›®åç§°"] = str(g["project"])
                    df_final["ä¾›åº”å•†åç§°"] = str(g["supplier"])
                    df_final["è¯¢ä»·äºº"] = str(g["enquirer"])
                    df_final["è¯¢ä»·æ—¥æœŸ"] = str(g["date"])
                    if need_global_currency and g.get("currency"):
                        df_final["å¸ç§"] = str(g["currency"])

                    overall_required = ["é¡¹ç›®åç§°","ä¾›åº”å•†åç§°","è¯¢ä»·äºº","è®¾å¤‡ææ–™åç§°","å“ç‰Œ","è®¾å¤‡å•ä»·","å¸ç§","è¯¢ä»·æ—¥æœŸ"]
                    def normalize_cell(x):
                        if pd.isna(x):
                            return None
                        s = str(x).strip()
                        if s.lower() in ("", "nan", "none"):
                            return None
                        return s

                    # --------------- åˆ†ç¦»å¯å¯¼å…¥ä¸ä¸å¯å¯¼å…¥çš„è®°å½• ---------------
                    check_df = df_final[overall_required].applymap(normalize_cell)
                    rows_missing_mask = check_df.isna().any(axis=1)

                    df_valid = df_final[~rows_missing_mask].copy()
                    df_invalid = df_final[rows_missing_mask].copy()

                    imported_count = 0

                    # å…ˆå¯¼å…¥æ‰€æœ‰æœ‰æ•ˆè¡Œï¼ˆå¦‚æœæœ‰ï¼‰
                    if not df_valid.empty:
                        try:
                            df_to_store = df_valid.dropna(how="all").drop_duplicates().reset_index(drop=True)

                            # æœ€ç»ˆä¸šåŠ¡å¿…å¡«æ£€æŸ¥ï¼ˆä¿é™©ï¼‰
                            final_check = df_to_store[["è®¾å¤‡ææ–™åç§°","å“ç‰Œ","è®¾å¤‡å•ä»·","å¸ç§"]].applymap(normalize_cell)
                            final_invalid_mask = final_check.isna().any(axis=1)

                            if final_invalid_mask.any():
                                to_import = df_to_store[~final_invalid_mask].copy()
                                still_bad = df_to_store[final_invalid_mask].copy()
                                if not to_import.empty:
                                    with engine.begin() as conn:
                                        to_import.to_sql("quotations", conn, if_exists="append", index=False)
                                    imported_count = len(to_import)
                                    st.success(f"âœ… å·²å¯¼å…¥ {imported_count} æ¡æœ‰æ•ˆè®°å½•ï¼ˆè·³è¿‡ {len(still_bad)} æ¡åœ¨æœ€ç»ˆä¸šåŠ¡å¿…å¡«ä¸­è¢«åˆ¤ä¸ºä¸å®Œæ•´ï¼‰ã€‚")
                                else:
                                    st.info("æ²¡æœ‰å¯å¯¼å…¥çš„æœ‰æ•ˆè®°å½•ï¼ˆæ‰€æœ‰å€™é€‰åœ¨æœ€ç»ˆæ£€æŸ¥ä¸­è¢«åˆ¤ä¸ºä¸å®Œæ•´ï¼‰ã€‚")
                                if not still_bad.empty:
                                    df_invalid = pd.concat([df_invalid, still_bad], ignore_index=True)
                            else:
                                with engine.begin() as conn:
                                    df_to_store.to_sql("quotations", conn, if_exists="append", index=False)
                                imported_count = len(df_to_store)
                                st.success(f"âœ… å·²å¯¼å…¥å…¨éƒ¨ {imported_count} æ¡æœ‰æ•ˆè®°å½•ã€‚")
                        except Exception as e:
                            st.error(f"å¯¼å…¥æœ‰æ•ˆè®°å½•æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
                    else:
                        st.info("æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³æ€»ä½“å¿…å¡«æ¡ä»¶çš„è®°å½•å¯å¯¼å…¥ã€‚")

                    # å±•ç¤ºå¹¶æä¾›ä¸‹è½½æœªé€šè¿‡çš„è®°å½•ï¼ˆå¦‚æœæœ‰ï¼‰
                    if not df_invalid.empty:
                        st.warning(f"ä»¥ä¸‹ {len(df_invalid)} æ¡è®°å½•ç¼ºå°‘æ€»ä½“å¿…å¡«å­—æ®µï¼ˆ{', '.join(overall_required)} ä¸­è‡³å°‘ä¸€é¡¹ï¼‰ï¼Œæœªè¢«å¯¼å…¥ï¼Œè¯·ä¿®æ­£åå†æ¬¡å¯¼å…¥ï¼š")
                        safe_st_dataframe(normalize_for_display(df_invalid).head(50))
                        buf_bad = io.BytesIO()
                        with pd.ExcelWriter(buf_bad, engine="openpyxl") as w:
                            df_invalid.to_excel(w, index=False)
                        buf_bad.seek(0)
                        st.download_button("ğŸ“¥ ä¸‹è½½æœªé€šè¿‡è®°å½•ï¼ˆç”¨äºä¿®æ­£ï¼‰", buf_bad, "invalid_rows.xlsx")
                    else:
                        st.info("æ‰€æœ‰è®°å½•å‡é€šè¿‡æ€»ä½“å¿…å¡«æ ¡éªŒå¹¶å·²å¯¼å…¥ï¼ˆè‹¥å·²æœ‰å¯¼å…¥è¯·æ³¨æ„ä¸è¦é‡å¤å¯¼å…¥åŒä¸€æ–‡ä»¶ï¼‰ã€‚")

                    # å¯¼å…¥å®Œæˆåæ¸…ç†çŠ¶æ€ï¼šä¿ç•™ mapping ä»¥ä¾¿ç”¨æˆ·ä¿®æ­£å¹¶é‡è¯•ï¼Œä½†æ¸…é™¤ bulk_applied
                    if imported_count > 0:
                        st.session_state["bulk_applied"] = False
                        st.info("å¯¼å…¥æµç¨‹å·²å®Œæˆï¼Œå·²æ¸…é™¤â€œå·²åº”ç”¨å…¨å±€â€æ ‡å¿—ã€‚è‹¥éœ€å†æ¬¡å¯¼å…¥å‰©ä½™è®°å½•ï¼Œè¯·ä¿®æ”¹æ˜ å°„æˆ–å…¨å±€ä¿¡æ¯åé‡è¯•ã€‚")

    # 2ï¸âƒ£ æ‰‹å·¥å½•å…¥
    st.header("âœï¸ è®¾å¤‡æ‰‹å·¥å½•å…¥")
    with st.form("device_form"):
        col1, col2, col3 = st.columns(3)
        pj = col1.text_input("é¡¹ç›®åç§°")
        sup = col2.text_input("ä¾›åº”å•†åç§°")
        inq = col3.text_input("è¯¢ä»·äºº")
        name = st.text_input("è®¾å¤‡ææ–™åç§°")
        brand = st.text_input("å“ç‰Œ")
        qty = st.number_input("æ•°é‡ç¡®è®¤", min_value=0.0)
        price = st.number_input("è®¾å¤‡å•ä»·", min_value=0.0)
        cur = st.selectbox("å¸ç§", ["IDR","USD","RMB","SGD","MYR","THB"])
        desc = st.text_area("æè¿°ï¼ˆå¯é€‰ï¼‰")
        remark = st.text_area("å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰")
        date = st.date_input("è¯¢ä»·æ—¥æœŸ")
        ok = st.form_submit_button("â• æ·»åŠ è®°å½•")
    if ok:
        if not (pj and sup and inq and name and brand):
            st.error("âŒ å¿…å¡«é¡¹ä¸èƒ½ä¸ºç©º")
        else:
            with engine.begin() as conn:
                conn.execute(text("""
                INSERT INTO quotations (é¡¹ç›®åç§°,ä¾›åº”å•†åç§°,è¯¢ä»·äºº,è®¾å¤‡ææ–™åç§°,å“ç‰Œ,æ•°é‡ç¡®è®¤,
                è®¾å¤‡å•ä»·,å¸ç§,æè¿°,å¤‡æ³¨,è¯¢ä»·æ—¥æœŸ,å½•å…¥äºº,åœ°åŒº)
                VALUES (:p,:s,:i,:n,:b,:q,:pr,:c,:d,:r,:dt,:u,:reg)
                """), {"p": pj,"s": sup,"i": inq,"n": name,"b": brand,"q": qty,"pr": price,"c": cur,
                        "d": desc,"r": remark,"dt": str(date),"u": user["username"],"reg": user["region"]})
            st.success("âœ… å·²æ·»åŠ è®°å½•ã€‚")

    # 3ï¸âƒ£ æ‚è´¹å½•å…¥
    st.header("ğŸ’° æ‚è´¹å½•å…¥")
    with st.form("misc_form"):
        pj = st.text_input("é¡¹ç›®åç§°")
        cat = st.text_input("æ‚è´¹ç±»ç›®")
        amt = st.number_input("é‡‘é¢", min_value=0.0)
        cur = st.selectbox("å¸ç§", ["IDR","USD","RMB","SGD","MYR","THB"])
        ok = st.form_submit_button("â• æ·»åŠ æ‚è´¹")
    if ok:
        if not pj or not cat:
            st.error("âŒ å¿…å¡«é¡¹ä¸èƒ½ä¸ºç©º")
        else:
            with engine.begin() as conn:
                conn.execute(text("""
                INSERT INTO misc_costs (é¡¹ç›®åç§°,æ‚è´¹ç±»ç›®,é‡‘é¢,å¸ç§,å½•å…¥äºº,åœ°åŒº)
                VALUES (:p,:c,:a,:cur,:u,:r)
                """), {"p": pj,"c": cat,"a": amt,"cur": cur,"u": user["username"],"r": user["region"]})
            st.success("âœ… æ‚è´¹å·²æ·»åŠ ã€‚")

# ============ æŸ¥è¯¢æ¨¡å— ============
elif page == "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢":
    st.header("ğŸ“‹ è®¾å¤‡æŸ¥è¯¢")
    kw = st.text_input("å…³é”®è¯ï¼ˆæŒ‰é€‰å®šå­—æ®µæœç´¢ï¼‰")
    search_fields = st.multiselect("é€‰æ‹©è¦åœ¨å…¶å†…æœç´¢å…³é”®è¯ï¼ˆä¸é€‰åˆ™åœ¨é»˜è®¤å­—æ®µæœç´¢ï¼‰",
                                   ["è®¾å¤‡ææ–™åç§°", "æè¿°", "å“ç‰Œ", "è§„æ ¼æˆ–å‹å·", "é¡¹ç›®åç§°", "ä¾›åº”å•†åç§°", "åœ°åŒº"])
    pj = st.text_input("æŒ‰é¡¹ç›®åç§°è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰")
    sup = st.text_input("æŒ‰ä¾›åº”å•†åç§°è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰")
    brand_f = st.text_input("æŒ‰å“ç‰Œè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰")
    cur = st.selectbox("å¸ç§", ["å…¨éƒ¨","IDR","USD","RMB","SGD","MYR","THB"], index=0)

    regions_options = ["å…¨éƒ¨","Singapore","Malaysia","Thailand","Indonesia","Vietnam","Philippines","Others","All"]
    if user["role"] == "admin":
        region_filter = st.selectbox("æŒ‰åœ°åŒºè¿‡æ»¤ï¼ˆç®¡ç†å‘˜å¯é€‰ï¼‰", regions_options, index=0)
    else:
        st.info(f"ä»…æ˜¾ç¤ºæ‚¨æ‰€åœ¨åœ°åŒºçš„æ•°æ®ï¼š{user['region']}")
        region_filter = user["region"]

    if st.button("ğŸ” æœç´¢è®¾å¤‡"):
        if not (kw or pj or sup or brand_f or (cur != "å…¨éƒ¨") or (user["role"]=="admin" and region_filter and region_filter!="å…¨éƒ¨")):
            st.warning("è¯·è¾“å…¥å…³é”®è¯æˆ–è‡³å°‘ä¸€ä¸ªè¿‡æ»¤æ¡ä»¶ã€‚")
        else:
            cond, params = [], {}
            if pj:
                cond.append("LOWER(é¡¹ç›®åç§°) LIKE :pj")
                params["pj"] = f"%{pj.lower()}%"
            if sup:
                cond.append("LOWER(ä¾›åº”å•†åç§°) LIKE :sup")
                params["sup"] = f"%{sup.lower()}%"
            if brand_f:
                cond.append("LOWER(å“ç‰Œ) LIKE :brand")
                params["brand"] = f"%{brand_f.lower()}%"
            if cur != "å…¨éƒ¨":
                cond.append("å¸ç§=:c")
                params["c"] = cur
            if user["role"] != "admin":
                cond.append("åœ°åŒº=:r")
                params["r"] = user["region"]
            else:
                if region_filter and region_filter != "å…¨éƒ¨":
                    cond.append("åœ°åŒº=:r")
                    params["r"] = region_filter

            if kw:
                tokens = re.findall(r"\S+", kw)
                if search_fields:
                    fields_to_search = search_fields
                else:
                    fields_to_search = ["è®¾å¤‡ææ–™åç§°","æè¿°","å“ç‰Œ","è§„æ ¼æˆ–å‹å·","é¡¹ç›®åç§°","ä¾›åº”å•†åç§°"]
                for i, token in enumerate(tokens):
                    ors = []
                    for j, f in enumerate(fields_to_search):
                        param_name = f"kw_{i}_{j}"
                        ors.append(f"LOWER({f}) LIKE :{param_name}")
                        params[param_name] = f"%{token.lower()}%"
                    cond.append("(" + " OR ".join(ors) + ")")

            sql = "SELECT * FROM quotations"
            if cond:
                sql += " WHERE " + " AND ".join(cond)
            df = pd.read_sql(sql, engine, params=params)
            safe_st_dataframe(df)
            if not df.empty:
                buf = io.BytesIO()
                with pd.ExcelWriter(buf, engine="openpyxl") as w:
                    df.to_excel(w, index=False)
                buf.seek(0)
                st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ", buf, "è®¾å¤‡æŸ¥è¯¢ç»“æœ.xlsx")

elif page == "ğŸ’° æ‚è´¹æŸ¥è¯¢":
    st.header("ğŸ’° æ‚è´¹æŸ¥è¯¢")
    pj2 = st.text_input("æŒ‰é¡¹ç›®åç§°è¿‡æ»¤")
    if st.button("ğŸ” æœç´¢æ‚è´¹"):
        params = {"pj": f"%{pj2.lower()}%"}
        sql = "SELECT * FROM misc_costs WHERE LOWER(é¡¹ç›®åç§°) LIKE :pj"
        if user["role"] != "admin":
            sql += " AND åœ°åŒº=:r"
            params["r"] = user["region"]
        df2 = pd.read_sql(sql, engine, params=params)
        safe_st_dataframe(df2)
        if not df2.empty:
            buf2 = io.BytesIO()
            with pd.ExcelWriter(buf2, engine="openpyxl") as w:
                df2.to_excel(w, index=False)
            buf2.seek(0)
            st.download_button("ğŸ“¥ ä¸‹è½½æ‚è´¹ç»“æœ", buf2, "æ‚è´¹æŸ¥è¯¢ç»“æœ.xlsx")

elif page == "ğŸ‘‘ ç®¡ç†å‘˜åå°" and user["role"] == "admin":
    st.header("ğŸ‘‘ ç®¡ç†å‘˜åå°")
    users_df = pd.read_sql("SELECT username, role, region FROM users", engine)
    safe_st_dataframe(users_df)
