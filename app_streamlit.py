# -*- coding: utf-8 -*-
"""
Complete app_streamlit.py â€” integrated, fixed, with adjusted validation rules:
- safe_rerun() compatibility wrapper
- normalize_for_display / safe_st_dataframe to avoid pyarrow serialization errors
- detect_header_from_preview + auto_map_header for smart header detection
- Robust mapped_but_empty detection that handles Series/DataFrame/multi-source mappings
- "å¡«å†™å…¨å±€ä¿¡æ¯" flow: shows explicit button to expand the global form (uses mapping_csv from session),
  fills only empty cells, validates required fields, imports valid rows with download of invalid rows
- Admin delete flow verifies rowids, attempts archival, deletes and checks rowcount, then refreshes
- Validation rules updated:
  - "å“ç‰Œ" is no longer a mandatory field
  - Price rule: either "è®¾å¤‡å•ä»·" or "äººå·¥åŒ…å¹²å•ä»·" must be provided (at least one)
- Manual input forms updated to reflect that "å“ç‰Œ" is not required
"""
import streamlit as st
import pandas as pd
from sqlalchemy import create_engine, text
import hashlib, io, re
from datetime import date

st.set_page_config(page_title="CMI è¯¢ä»·å½•å…¥ä¸æŸ¥è¯¢å¹³å°", layout="wide")

# --- Compatibility helper: safe_rerun ---
def safe_rerun():
    try:
        if hasattr(st, "experimental_rerun"):
            st.experimental_rerun()
            return
        try:
            from streamlit.runtime.scriptrunner import RerunException
            raise RerunException()
        except Exception:
            st.session_state["_needs_refresh"] = True
            st.warning("è¯·æ‰‹åŠ¨åˆ·æ–°é¡µé¢ä»¥æŸ¥çœ‹æœ€æ–°çŠ¶æ€ï¼ˆè‡ªåŠ¨åˆ·æ–°åœ¨å½“å‰ Streamlit ç‰ˆæœ¬ä¸å¯ç”¨ï¼‰ã€‚")
            return
    except Exception:
        st.session_state["_needs_refresh"] = True
        st.warning("æ— æ³•è‡ªåŠ¨é‡å¯ï¼Œè¯·æ‰‹åŠ¨åˆ·æ–°æµè§ˆå™¨é¡µé¢ã€‚")
        return

# Database engine (adjust URI for production)
engine = create_engine("sqlite:///quotation.db", connect_args={"check_same_thread": False})

# ============ Initialize DB (idempotent) ============
with engine.begin() as conn:
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT UNIQUE,
        password TEXT,
        role TEXT CHECK(role IN ('admin','user')),
        region TEXT
    )"""))
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS quotations (
        åºå· TEXT,
        è®¾å¤‡ææ–™åç§° TEXT NOT NULL,
        è§„æ ¼æˆ–å‹å· TEXT,
        æè¿° TEXT,
        å“ç‰Œ TEXT,
        å•ä½ TEXT,
        æ•°é‡ç¡®è®¤ REAL,
        æŠ¥ä»·å“ç‰Œ TEXT,
        å‹å· TEXT,
        è®¾å¤‡å•ä»· REAL,
        è®¾å¤‡å°è®¡ REAL,
        äººå·¥åŒ…å¹²å•ä»· REAL,
        äººå·¥åŒ…å¹²å°è®¡ REAL,
        ç»¼åˆå•ä»·æ±‡æ€» REAL,
        å¸ç§ TEXT,
        åŸå‚å“ç‰Œç»´ä¿æœŸé™ TEXT,
        è´§æœŸ TEXT,
        å¤‡æ³¨ TEXT,
        è¯¢ä»·äºº TEXT,
        é¡¹ç›®åç§° TEXT,
        ä¾›åº”å•†åç§° TEXT,
        è¯¢ä»·æ—¥æœŸ TEXT,
        å½•å…¥äºº TEXT,
        åœ°åŒº TEXT
    )"""))
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS misc_costs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        é¡¹ç›®åç§° TEXT,
        æ‚è´¹ç±»ç›® TEXT,
        é‡‘é¢ REAL,
        å¸ç§ TEXT,
        å½•å…¥äºº TEXT,
        åœ°åŒº TEXT
    )"""))
    # default admin
    conn.execute(text("""
    INSERT OR IGNORE INTO users (username, password, role, region)
    VALUES ('admin', :pw, 'admin', 'All')"""), {"pw": hashlib.sha256("admin123".encode()).hexdigest()})

# ============ Config / Helpers ============
HEADER_SYNONYMS = {
    "åºå·":"åºå·","no":"åºå·","index":"åºå·",
    "è®¾å¤‡ææ–™åç§°":"è®¾å¤‡ææ–™åç§°","è®¾å¤‡åç§°":"è®¾å¤‡ææ–™åç§°","material":"è®¾å¤‡ææ–™åç§°","name":"è®¾å¤‡ææ–™åç§°",
    "è§„æ ¼æˆ–å‹å·":"è§„æ ¼æˆ–å‹å·","è§„æ ¼":"è§„æ ¼æˆ–å‹å·","model":"è§„æ ¼æˆ–å‹å·","spec":"è§„æ ¼æˆ–å‹å·",
    "æè¿°":"æè¿°","description":"æè¿°",
    "å“ç‰Œ":"å“ç‰Œ","brand":"å“ç‰Œ",
    "å•ä½":"å•ä½","unit":"å•ä½",
    "æ•°é‡ç¡®è®¤":"æ•°é‡ç¡®è®¤","æ•°é‡":"æ•°é‡ç¡®è®¤","qty":"æ•°é‡ç¡®è®¤","quantity":"æ•°é‡ç¡®è®¤",
    "æŠ¥ä»·å“ç‰Œ":"æŠ¥ä»·å“ç‰Œ","æŠ¥ä»·":"æŠ¥ä»·å“ç‰Œ",
    "å‹å·":"å‹å·",
    "è®¾å¤‡å•ä»·":"è®¾å¤‡å•ä»·","å•ä»·":"è®¾å¤‡å•ä»·","price":"è®¾å¤‡å•ä»·",
    "è®¾å¤‡å°è®¡":"è®¾å¤‡å°è®¡","subtotal":"è®¾å¤‡å°è®¡",
    "å¸ç§":"å¸ç§","currency":"å¸ç§",
    "è¯¢ä»·äºº":"è¯¢ä»·äºº","é¡¹ç›®åç§°":"é¡¹ç›®åç§°","ä¾›åº”å•†åç§°":"ä¾›åº”å•†åç§°","è¯¢ä»·æ—¥æœŸ":"è¯¢ä»·æ—¥æœŸ","å½•å…¥äºº":"å½•å…¥äºº","åœ°åŒº":"åœ°åŒº"
}
DB_COLUMNS = ["åºå·","è®¾å¤‡ææ–™åç§°","è§„æ ¼æˆ–å‹å·","æè¿°","å“ç‰Œ","å•ä½","æ•°é‡ç¡®è®¤",
              "æŠ¥ä»·å“ç‰Œ","å‹å·","è®¾å¤‡å•ä»·","è®¾å¤‡å°è®¡","äººå·¥åŒ…å¹²å•ä»·","äººå·¥åŒ…å¹²å°è®¡",
              "ç»¼åˆå•ä»·æ±‡æ€»","å¸ç§","åŸå‚å“ç‰Œç»´ä¿æœŸé™","è´§æœŸ","å¤‡æ³¨",
              "è¯¢ä»·äºº","é¡¹ç›®åç§°","ä¾›åº”å•†åç§°","è¯¢ä»·æ—¥æœŸ","å½•å…¥äºº","åœ°åŒº"]

def auto_map_header(orig_header: str):
    if orig_header is None:
        return None
    h = str(orig_header).strip().lower()
    for k, v in HEADER_SYNONYMS.items():
        if h == k.lower():
            return v
    h_norm = re.sub(r"[\s\-\_ï¼š:ï¼ˆï¼‰()]+", " ", h).strip()
    for k, v in HEADER_SYNONYMS.items():
        if h_norm == re.sub(r"[\s\-\_ï¼š:ï¼ˆï¼‰()]+", " ", k.lower()).strip():
            return v
    for k, v in HEADER_SYNONYMS.items():
        if k.lower() in h or h in k.lower():
            return v
    return None

def detect_header_from_preview(df_preview: pd.DataFrame, max_header_rows=2, max_search_rows=8):
    if df_preview is None or df_preview.shape[0] == 0:
        return None, None
    nrows, ncols = df_preview.shape
    search_rows = min(max_search_rows, nrows)
    best = {"score": -1}
    for start in range(search_rows):
        for rows_used in range(1, max_header_rows + 1):
            if start + rows_used > nrows:
                continue
            cand = []
            nonempty = 0
            mapped = 0
            for col in range(ncols):
                parts = []
                for r in range(start, start + rows_used):
                    cell = df_preview.iat[r, col]
                    if pd.isna(cell):
                        continue
                    s = str(cell).strip()
                    if s:
                        parts.append(s)
                header_text = " ".join(parts).strip()
                if header_text:
                    nonempty += 1
                cand.append(header_text)
                if header_text and auto_map_header(header_text):
                    mapped += 1
            score = mapped + 0.5 * nonempty
            if score > best["score"]:
                best = {"score": score, "header": cand, "row": start, "rows_used": rows_used, "mapped": mapped, "nonempty": nonempty}
    if best.get("header") is not None:
        if best["mapped"] >= 2 or (best["nonempty"] > 0 and (best["mapped"] / best["nonempty"]) >= 0.3):
            return best["header"], best["row"] + best["rows_used"] - 1
    return None, None

def normalize_for_display(df: pd.DataFrame) -> pd.DataFrame:
    if df is None:
        return df
    df_disp = df.copy()
    for col in df_disp.columns:
        try:
            ser = df_disp[col]
            if isinstance(ser, pd.DataFrame):
                df_disp[col] = ser.astype(str).apply(lambda x: x.str.slice(0, 100)).astype(str)
                continue
            if ser.dtype == "object":
                non_null = ser.dropna()
                if non_null.empty:
                    df_disp[col] = ser.where(ser.notna(), "").astype(str)
                    continue
                types_seen = {type(x) for x in non_null}
                has_bytes = any(isinstance(x, (bytes, bytearray, memoryview)) for x in non_null)
                multiple_types = len(types_seen) > 1
                if has_bytes or multiple_types:
                    df_disp[col] = ser.where(ser.notna(), None).apply(lambda x: "" if x is None else str(x))
                else:
                    df_disp[col] = ser.where(ser.notna(), None).apply(lambda x: "" if x is None else x)
        except Exception:
            df_disp[col] = df_disp[col].where(df_disp[col].notna(), None).apply(lambda x: "" if x is None else str(x))
    return df_disp

def safe_st_dataframe(df: pd.DataFrame, height: int | None = None):
    df_disp = normalize_for_display(df)
    try:
        if height is None:
            st.dataframe(df_disp)
        else:
            st.dataframe(df_disp, height=height)
    except Exception:
        df2 = df_disp.copy()
        for col in df2.columns:
            df2[col] = df2[col].astype(str).fillna("")
        if height is None:
            st.dataframe(df2)
        else:
            st.dataframe(df2, height=height)

# ============ Auth UI ============
def login_form():
    st.subheader("ğŸ” ç”¨æˆ·ç™»å½•")
    u = st.text_input("ç”¨æˆ·å", key="login_user")
    p = st.text_input("å¯†ç ", type="password", key="login_pass")
    if st.button("ç™»å½•", key="login_button"):
        if not u or not p:
            st.error("è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ")
            return
        pw_hash = hashlib.sha256(p.encode()).hexdigest()
        with engine.begin() as conn:
            user = conn.execute(text("SELECT username, role, region FROM users WHERE username=:u AND password=:p"),
                                {"u": u, "p": pw_hash}).fetchone()
        if user:
            st.session_state["user"] = {"username": user.username, "role": user.role, "region": user.region}
            st.success(f"ç™»å½•æˆåŠŸï¼š{user.username}")
            safe_rerun()
        else:
            st.error("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

def register_form():
    st.subheader("ğŸ§¾ æ³¨å†Œ")
    ru = st.text_input("æ–°ç”¨æˆ·å", key="reg_user")
    rp = st.text_input("æ–°å¯†ç ", type="password", key="reg_pass")
    region = st.selectbox("åœ°åŒº", ["Singapore","Malaysia","Thailand","Indonesia","Vietnam","Philippines","Others"])
    if st.button("æ³¨å†Œ", key="reg_button"):
        if not ru or not rp:
            st.warning("ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º")
        else:
            pw_hash = hashlib.sha256(rp.encode()).hexdigest()
            try:
                with engine.begin() as conn:
                    conn.execute(text("INSERT INTO users (username,password,role,region) VALUES (:u,:p,'user',:r)"),
                                 {"u": ru, "p": pw_hash, "r": region})
                st.success("æ³¨å†ŒæˆåŠŸï¼Œè¯·ç™»å½•")
            except Exception:
                st.error("ç”¨æˆ·åå·²å­˜åœ¨")

def logout():
    if "user" in st.session_state:
        del st.session_state["user"]
    safe_rerun()

# ============ Page flow ============
if "user" not in st.session_state:
    tabs = st.tabs(["ğŸ”‘ ç™»å½•","ğŸ§¾ æ³¨å†Œ"])
    with tabs[0]:
        login_form()
    with tabs[1]:
        register_form()
    st.stop()

if st.session_state.get("_needs_refresh", False):
    if st.button("æ‰‹åŠ¨åˆ·æ–°é¡µé¢", key="manual_refresh"):
        safe_rerun()

user = st.session_state["user"]
st.sidebar.markdown(f"ğŸ‘¤ **{user['username']}**  \nğŸ¢ åœ°åŒºï¼š{user['region']}  \nğŸ”‘ è§’è‰²ï¼š{user['role']}")
if st.sidebar.button("é€€å‡ºç™»å½•", key="logout_btn"):
    logout()

page = st.sidebar.radio("å¯¼èˆª", ["ğŸ  ä¸»é¡µé¢", "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢", "ğŸ’° æ‚è´¹æŸ¥è¯¢", "ğŸ‘‘ ç®¡ç†å‘˜åå°"] if user["role"]=="admin" else ["ğŸ  ä¸»é¡µé¢", "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢", "ğŸ’° æ‚è´¹æŸ¥è¯¢"])

# ============ Main: Upload / Mapping / Import ============
if page == "ğŸ  ä¸»é¡µé¢":
    st.title("ğŸ“Š è¯¢ä»·å½•å…¥ä¸æŸ¥è¯¢å¹³å°")
    st.header("ğŸ“‚ Excel æ‰¹é‡å½•å…¥ï¼ˆæ™ºèƒ½è¡¨å¤´æ˜ å°„ï¼‰")
    st.caption("ç³»ç»Ÿä¼šå°è¯•è¯†åˆ«ä¸Šä¼ æ–‡ä»¶çš„è¡¨å¤´å¹¶ç»™å‡ºå»ºè®®æ˜ å°„ã€‚")

    template = pd.DataFrame(columns=[c for c in DB_COLUMNS if c not in ("å½•å…¥äºº","åœ°åŒº")])
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        template.to_excel(writer, index=False)
    buf.seek(0)
    st.download_button("ä¸‹è½½æ¨¡æ¿", buf, "quotation_template.xlsx", key="download_template")

    uploaded = st.file_uploader("ä¸Šä¼  Excel (.xlsx)", type=["xlsx"], key="upload_excel")
    if uploaded:
        # ensure session flags
        if "mapping_done" not in st.session_state:
            st.session_state["mapping_done"] = False
        if "bulk_applied" not in st.session_state:
            st.session_state["bulk_applied"] = False

        try:
            preview = pd.read_excel(uploaded, header=None, nrows=50, dtype=object)
            safe_st_dataframe(preview.head(10))
        except Exception as e:
            st.error(f"è¯»å–é¢„è§ˆå¤±è´¥ï¼š{e}")
            preview = None

        if preview is not None:
            header_names, header_row_index = detect_header_from_preview(preview, max_header_rows=2, max_search_rows=8)
            raw_df_full = pd.read_excel(uploaded, header=None, dtype=object)
            if header_names is None:
                header_row_index = 0
                header_names = [str(x) if not pd.isna(x) else "" for x in raw_df_full.iloc[0].tolist()]
            data_df = raw_df_full.iloc[header_row_index+1 : ].copy().reset_index(drop=True)
            if len(header_names) < data_df.shape[1]:
                header_names += [f"Unnamed_{i}" for i in range(len(header_names), data_df.shape[1])]
            elif len(header_names) > data_df.shape[1]:
                header_names = header_names[:data_df.shape[1]]

            data_df.columns = header_names

            st.markdown("**æ£€æµ‹åˆ°çš„åŸå§‹è¡¨å¤´ï¼ˆç”¨äºæ˜ å°„ï¼Œç³»ç»Ÿå·²å°è¯•è‡ªåŠ¨å¯¹åº”ä¸€ç‰ˆå»ºè®®ï¼‰ï¼š**")
            st.write(list(data_df.columns))

            mapping_targets = ["Ignore"] + [c for c in DB_COLUMNS if c not in ("å½•å…¥äºº","åœ°åŒº")]

            auto_defaults = {}
            for col in data_df.columns:
                auto_val = auto_map_header(col)
                if auto_val and auto_val in mapping_targets:
                    auto_defaults[col] = auto_val
                else:
                    auto_defaults[col] = "Ignore"

            st.markdown("ç³»ç»Ÿå·²ä¸ºæ¯ä¸€åˆ—ç”Ÿæˆå»ºè®®æ˜ å°„ï¼ˆä½ å¯ä»¥ç›´æ¥ç‚¹å‡»â€œåº”ç”¨æ˜ å°„å¹¶é¢„è§ˆâ€ æˆ– ä¿®æ”¹ä»»æ„ä¸‹æ‹‰å†æäº¤ï¼‰ã€‚")

            mapped_choices = {}
            with st.form("mapping_form", clear_on_submit=False):
                cols_left, cols_right = st.columns(2)
                for i, col in enumerate(data_df.columns):
                    default = auto_defaults.get(col, "Ignore")
                    container = cols_left if i % 2 == 0 else cols_right
                    sel = container.selectbox(f"æºåˆ—: {col}", mapping_targets,
                                              index = mapping_targets.index(default) if default in mapping_targets else 0,
                                              key=f"map_{i}")
                    mapped_choices[col] = sel
                submitted = st.form_submit_button("åº”ç”¨æ˜ å°„å¹¶é¢„è§ˆ")

            if submitted:
                target_sources = {}
                for src, tgt in mapped_choices.items():
                    if tgt != "Ignore":
                        target_sources.setdefault(tgt, []).append(src)

                # robust mapped_but_empty detection
                mapped_but_empty = []
                for tgt, srcs in target_sources.items():
                    has_value = False
                    src_list = []
                    for item in srcs:
                        if isinstance(item, (list, tuple, set)):
                            src_list.extend(item)
                        else:
                            src_list.append(item)
                    for src_col in src_list:
                        if src_col in data_df.columns:
                            col_obj = data_df[src_col]
                            if isinstance(col_obj, pd.DataFrame):
                                try:
                                    ser = col_obj.fillna("").astype(str).agg(" ".join, axis=1)
                                except Exception:
                                    ser = col_obj.iloc[:, 0].astype(object)
                            else:
                                ser = col_obj.astype(object)

                            def normalize_val(x):
                                if pd.isna(x):
                                    return pd.NA
                                sx = str(x).strip()
                                if sx.lower() in ("", "nan", "none"):
                                    return pd.NA
                                return sx

                            try:
                                ser_norm = ser.map(normalize_val)
                            except Exception:
                                ser_norm = ser.astype(str).map(lambda x: None if x is None else (str(x).strip() if str(x).strip().lower() not in ("", "nan", "none") else pd.NA))

                            if ser_norm.notna().any():
                                has_value = True
                                break
                    if not has_value:
                        mapped_but_empty.append(tgt)

                # build df_for_db
                rename_dict = {orig: mapped for orig, mapped in mapped_choices.items() if mapped != "Ignore"}
                df_mapped = data_df.rename(columns=rename_dict).copy()
                for c in DB_COLUMNS:
                    if c not in df_mapped.columns:
                        df_mapped[c] = pd.NA
                df_mapped["å½•å…¥äºº"] = user["username"]
                df_mapped["åœ°åŒº"] = user["region"]
                df_for_db = df_mapped[DB_COLUMNS]

                # save mapping to session
                csv_buf = io.StringIO()
                df_for_db.to_csv(csv_buf, index=False)
                st.session_state["mapping_csv"] = csv_buf.getvalue()
                st.session_state["mapping_done"] = True
                st.session_state["mapping_rename_dict"] = rename_dict
                st.session_state["mapping_target_sources"] = target_sources
                st.session_state["mapping_mapped_but_empty"] = mapped_but_empty

                st.success("æ˜ å°„å·²ä¿å­˜ã€‚ç°åœ¨è¯·å¡«å†™å…¨å±€å¿…å¡«ä¿¡æ¯å¹¶æäº¤ä»¥ç»§ç»­æ ¡éªŒä¸å¯¼å…¥ã€‚")

    # ====== æ˜ å°„åé¢„è§ˆ + æ›´ç¨³å¥çš„â€œå¡«å†™å…¨å±€ä¿¡æ¯å¹¶å¯¼å…¥â€ æµç¨‹ ======
    mapping_csv = st.session_state.get("mapping_csv", None)
    if mapping_csv:
        try:
            csv_buf = io.StringIO(mapping_csv)
            df_for_db = pd.read_csv(csv_buf, dtype=object)
            for c in DB_COLUMNS:
                if c not in df_for_db.columns:
                    df_for_db[c] = pd.NA
            df_for_db = df_for_db[DB_COLUMNS]
        except Exception as e:
            st.error(f"æ¢å¤æ˜ å°„æ•°æ®å¤±è´¥ï¼š{e}")
            df_for_db = None

        st.markdown("**æ˜ å°„åé¢„è§ˆï¼ˆå‰ 10 è¡Œï¼‰ï¼š**")
        if df_for_db is not None:
            safe_st_dataframe(df_for_db.head(10))
        else:
            st.info("æ˜ å°„æ•°æ®æ— æ³•é¢„è§ˆï¼Œè¯·é‡æ–°æ˜ å°„ã€‚")

        if "show_global_form" not in st.session_state:
            st.session_state["show_global_form"] = False

        col_show, col_hint = st.columns([1, 6])
        if col_show.button("â¡ï¸ å¡«å†™/æŸ¥çœ‹å…¨å±€ä¿¡æ¯å¹¶åº”ç”¨å¯¼å…¥", key="open_global_form_btn"):
            st.session_state["show_global_form"] = True
        col_hint.markdown("ï¼ˆè‹¥éœ€è¦å¯¹ç©ºå€¼è¿›è¡Œç»Ÿä¸€å¡«å……ï¼Œä¾‹å¦‚å¸ç§/é¡¹ç›®/ä¾›åº”å•†/è¯¢ä»·äººï¼Œè¯·å±•å¼€å¹¶å¡«å†™å…¨å±€ä¿¡æ¯ï¼‰")

        if st.session_state["show_global_form"]:
            if "bulk_values" not in st.session_state:
                st.session_state["bulk_values"] = {"project": "", "supplier": "", "enquirer": "", "date": "", "currency": ""}

            def column_has_empty_currency(df: pd.DataFrame) -> bool:
                if df is None or "å¸ç§" not in df.columns:
                    return True
                ser = df["å¸ç§"]
                def is_empty_val(x):
                    if pd.isna(x):
                        return True
                    s = str(x).strip().lower()
                    return s == "" or s in ("nan", "none")
                return any(is_empty_val(x) for x in ser)

            need_global_currency = column_has_empty_currency(df_for_db)

            st.markdown("è¯·å¡«å†™å…¨å±€å¿…å¡«ä¿¡æ¯ï¼ˆä»…å¡«å……ç©ºå€¼ï¼‰ã€‚å¡«å†™å®Œåç‚¹å‡»â€œåº”ç”¨å…¨å±€å¹¶ç»§ç»­æ ¡éªŒâ€ï¼š")
            with st.form("global_form_v2"):
                g1, g2, g3, g4, g5 = st.columns(5)
                g_project = g1.text_input("é¡¹ç›®åç§°", key="global_project_input", value=st.session_state["bulk_values"].get("project", ""))
                g_supplier = g2.text_input("ä¾›åº”å•†åç§°", key="global_supplier_input", value=st.session_state["bulk_values"].get("supplier", ""))
                g_enquirer = g3.text_input("è¯¢ä»·äºº", key="global_enquirer_input", value=st.session_state["bulk_values"].get("enquirer", ""))
                default_date = st.session_state["bulk_values"].get("date", "")
                try:
                    if default_date:
                        g_date = g4.date_input("è¯¢ä»·æ—¥æœŸ", value=pd.to_datetime(default_date).date(), key="global_date_input")
                    else:
                        g_date = g4.date_input("è¯¢ä»·æ—¥æœŸ", value=date.today(), key="global_date_input")
                except Exception:
                    g_date = g4.date_input("è¯¢ä»·æ—¥æœŸ", value=date.today(), key="global_date_input")

                g_currency = None
                if need_global_currency:
                    currency_options = ["", "IDR", "USD", "RMB", "SGD", "MYR", "THB"]
                    curr_default = st.session_state["bulk_values"].get("currency", "")
                    default_idx = currency_options.index(curr_default) if curr_default in currency_options else 0
                    g_currency = g5.selectbox("å¸ç§ï¼ˆç”¨äºå¡«å……ç©ºå€¼ï¼‰", currency_options, index=default_idx, key="global_currency_input")
                else:
                    g5.write("")

                apply_global = st.form_submit_button("åº”ç”¨å…¨å±€å¹¶ç»§ç»­æ ¡éªŒ")

            if apply_global:
                if not (g_project and g_supplier and g_enquirer and g_date):
                    st.error("å¿…é¡»å¡«å†™ï¼šé¡¹ç›®åç§°ã€ä¾›åº”å•†åç§°ã€è¯¢ä»·äººå’Œè¯¢ä»·æ—¥æœŸ")
                    st.session_state["bulk_applied"] = False
                elif need_global_currency and (g_currency is None or str(g_currency).strip() == ""):
                    st.error("ç”±äºæºæ•°æ®å­˜åœ¨ç©ºçš„å¸ç§ï¼Œè¯·é€‰æ‹©å¸ç§ä»¥ç»§ç»­ã€‚")
                    st.session_state["bulk_applied"] = False
                else:
                    st.session_state["bulk_values"] = {
                        "project": str(g_project),
                        "supplier": str(g_supplier),
                        "enquirer": str(g_enquirer),
                        "date": str(g_date),
                        "currency": str(g_currency) if g_currency is not None else st.session_state["bulk_values"].get("currency", "")
                    }
                    st.session_state["bulk_applied"] = True
                    st.success("å·²åº”ç”¨å…¨å±€ä¿¡æ¯ï¼Œæ­£åœ¨è¿›è¡Œæ€»ä½“å¿…å¡«æ ¡éªŒ...")

            if st.session_state.get("bulk_applied", False):
                try:
                    csv_buf2 = io.StringIO(st.session_state["mapping_csv"])
                    df_for_db = pd.read_csv(csv_buf2, dtype=object)
                    for c in DB_COLUMNS:
                        if c not in df_for_db.columns:
                            df_for_db[c] = pd.NA
                    df_for_db = df_for_db[DB_COLUMNS]
                except Exception as e:
                    st.error(f"æ¢å¤æ˜ å°„æ•°æ®å¤±è´¥ï¼š{e}")
                    df_for_db = None

                if df_for_db is None:
                    st.error("æ˜ å°„æ•°æ®ä¸¢å¤±ï¼Œæ— æ³•ç»§ç»­å¯¼å…¥ã€‚")
                else:
                    df_final = df_for_db.copy()
                    g = st.session_state["bulk_values"]

                    def is_empty_cell(x):
                        if pd.isna(x):
                            return True
                        sx = str(x).strip()
                        return sx == "" or sx.lower() in ("nan", "none")

                    def fill_empty(col_name, value):
                        if col_name not in df_final.columns:
                            df_final[col_name] = pd.NA
                        mask = df_final[col_name].apply(lambda x: is_empty_cell(x))
                        if mask.any():
                            df_final.loc[mask, col_name] = value

                    fill_empty("é¡¹ç›®åç§°", str(g["project"]))
                    fill_empty("ä¾›åº”å•†åç§°", str(g["supplier"]))
                    fill_empty("è¯¢ä»·äºº", str(g["enquirer"]))
                    fill_empty("è¯¢ä»·æ—¥æœŸ", str(g["date"]))
                    if need_global_currency and g.get("currency"):
                        fill_empty("å¸ç§", str(g["currency"]))

                    # --- New validation: brand NOT required; price rule: either è®¾å¤‡å•ä»· or äººå·¥åŒ…å¹²å•ä»· must be present
                    def normalize_cell(x):
                        if pd.isna(x):
                            return None
                        s = str(x).strip()
                        if s.lower() in ("", "nan", "none"):
                            return None
                        return s

                    # required non-price fields (brand is NOT required)
                    required_nonprice = ["é¡¹ç›®åç§°","ä¾›åº”å•†åç§°","è¯¢ä»·äºº","è®¾å¤‡ææ–™åç§°","å¸ç§","è¯¢ä»·æ—¥æœŸ"]
                    check_nonprice = df_final[required_nonprice].applymap(normalize_cell)
                    missing_nonprice = check_nonprice.isna().any(axis=1)

                    def price_has_value(row) -> bool:
                        v1 = row.get("è®¾å¤‡å•ä»·", None) if "è®¾å¤‡å•ä»·" in row.index else None
                        v2 = row.get("äººå·¥åŒ…å¹²å•ä»·", None) if "äººå·¥åŒ…å¹²å•ä»·" in row.index else None
                        nv1 = normalize_cell(v1)
                        nv2 = normalize_cell(v2)
                        return (nv1 is not None) or (nv2 is not None)

                    price_mask = df_final.apply(price_has_value, axis=1)
                    rows_invalid_mask = missing_nonprice | (~price_mask)

                    df_valid = df_final[~rows_invalid_mask].copy()
                    df_invalid = df_final[rows_invalid_mask].copy()

                    imported_count = 0
                    if not df_valid.empty:
                        try:
                            df_to_store = df_valid.dropna(how="all").drop_duplicates().reset_index(drop=True)
                            # final check on critical cols: device name and price/labor-price rule already ensured
                            final_check = df_to_store[["è®¾å¤‡ææ–™åç§°","è®¾å¤‡å•ä»·","äººå·¥åŒ…å¹²å•ä»·","å¸ç§"]].applymap(normalize_cell)
                            # ensure price/labor present
                            def final_price_ok(row):
                                v1 = row.get("è®¾å¤‡å•ä»·", None)
                                v2 = row.get("äººå·¥åŒ…å¹²å•ä»·", None)
                                return (v1 is not None) or (v2 is not None)
                            final_invalid_mask = final_check["è®¾å¤‡ææ–™åç§°"].isna() | (~df_to_store.apply(final_price_ok, axis=1))
                            if final_invalid_mask.any():
                                to_import = df_to_store[~final_invalid_mask].copy()
                                still_bad = df_to_store[final_invalid_mask].copy()
                                if not to_import.empty:
                                    with engine.begin() as conn:
                                        to_import.to_sql("quotations", conn, if_exists="append", index=False)
                                    imported_count = len(to_import)
                                    st.success(f"âœ… å·²å¯¼å…¥ {imported_count} æ¡æœ‰æ•ˆè®°å½•ï¼ˆè·³è¿‡ {len(still_bad)} æ¡ï¼‰ã€‚")
                                else:
                                    st.info("æ²¡æœ‰å¯å¯¼å…¥çš„æœ‰æ•ˆè®°å½•ï¼ˆæ‰€æœ‰å€™é€‰åœ¨æœ€ç»ˆæ£€æŸ¥ä¸­è¢«åˆ¤ä¸ºä¸å®Œæ•´ï¼‰ã€‚")
                                if not still_bad.empty:
                                    df_invalid = pd.concat([df_invalid, still_bad], ignore_index=True)
                            else:
                                with engine.begin() as conn:
                                    df_to_store.to_sql("quotations", conn, if_exists="append", index=False)
                                imported_count = len(df_to_store)
                                st.success(f"âœ… å·²å¯¼å…¥å…¨éƒ¨ {imported_count} æ¡æœ‰æ•ˆè®°å½•ã€‚")
                        except Exception as e:
                            st.error(f"å¯¼å…¥æœ‰æ•ˆè®°å½•æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
                    else:
                        st.info("æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³æ€»ä½“å¿…å¡«æ¡ä»¶çš„è®°å½•å¯å¯¼å…¥ã€‚")

                    if not df_invalid.empty:
                        st.warning(f"ä»¥ä¸‹ {len(df_invalid)} æ¡è®°å½•ç¼ºå°‘æ€»ä½“å¿…å¡«å­—æ®µï¼Œæœªè¢«å¯¼å…¥ï¼Œè¯·ä¿®æ­£åé‡æ–°å¯¼å…¥ï¼š")
                        safe_st_dataframe(df_invalid.head(50))
                        buf_bad = io.BytesIO()
                        with pd.ExcelWriter(buf_bad, engine="openpyxl") as w:
                            df_invalid.to_excel(w, index=False)
                        buf_bad.seek(0)
                        st.download_button("ğŸ“¥ ä¸‹è½½æœªé€šè¿‡è®°å½•ï¼ˆç”¨äºä¿®æ­£ï¼‰", buf_bad, "invalid_rows.xlsx")

                    st.session_state["bulk_applied"] = False
    else:
        st.info("æ˜ å°„ä¿å­˜ã€‚è¯·å¡«å†™å…¨å±€ä¿¡æ¯ï¼ˆè‹¥å¿…è¦ï¼‰å¹¶åº”ç”¨ä»¥ç»§ç»­å¯¼å…¥ã€‚")

    # ------------------ æ‰‹å·¥å½•å…¥ï¼ˆåŸå§‹é€»è¾‘ï¼Œå·²è°ƒæ•´ï¼šå“ç‰Œä¸å†å¿…å¡«ï¼‰ ------------------
    st.header("âœï¸ æ‰‹å·¥å½•å…¥è®¾å¤‡ï¼ˆåŸå§‹é€»è¾‘ï¼‰")
    with st.form("manual_add_form_original", clear_on_submit=True):
        col1, col2, col3 = st.columns(3)
        pj = col1.text_input("é¡¹ç›®åç§°", key="manual_project_orig")
        sup = col2.text_input("ä¾›åº”å•†åç§°", key="manual_supplier_orig")
        inq = col3.text_input("è¯¢ä»·äºº", key="manual_enquirer_orig")
        name = st.text_input("è®¾å¤‡ææ–™åç§°", key="manual_name_orig")
        brand = st.text_input("å“ç‰Œï¼ˆå¯é€‰ï¼‰", key="manual_brand_orig")
        qty = st.number_input("æ•°é‡ç¡®è®¤", min_value=0.0, key="manual_qty_orig")
        price = st.number_input("è®¾å¤‡å•ä»·", min_value=0.0, key="manual_price_orig")
        labor_price = st.number_input("äººå·¥åŒ…å¹²å•ä»·", min_value=0.0, key="manual_labor_price_orig")
        cur = st.selectbox("å¸ç§", ["IDR","USD","RMB","SGD","MYR","THB"], key="manual_currency_orig")
        desc = st.text_area("æè¿°", key="manual_desc_orig")
        date_inq = st.date_input("è¯¢ä»·æ—¥æœŸ", value=date.today(), key="manual_date_orig")
        submit_manual = st.form_submit_button("æ·»åŠ è®°å½•ï¼ˆæ‰‹åŠ¨ï¼‰", key="manual_submit_orig")

    if submit_manual:
        # validate required fields except brand
        if not (pj and sup and inq and name):
            st.error("å¿…å¡«é¡¹ä¸èƒ½ä¸ºç©ºï¼šé¡¹ç›®åç§°ã€ä¾›åº”å•†åç§°ã€è¯¢ä»·äººã€è®¾å¤‡ææ–™åç§°")
        else:
            # price rule: either price or labor_price must be provided
            def has_price_value(v):
                if pd.isna(v):
                    return False
                s = str(v).strip()
                if s == "" or s.lower() in ("nan","none"):
                    return False
                return True
            if not (has_price_value(price) or has_price_value(labor_price)):
                st.error("è¯·è‡³å°‘å¡«å†™ è®¾å¤‡å•ä»· æˆ– äººå·¥åŒ…å¹²å•ä»· ä¸­çš„ä¸€é¡¹ï¼ˆä¸¤è€…è‡³å°‘å¡«ä¸€é¡¹ï¼‰ã€‚")
            else:
                try:
                    with engine.begin() as conn:
                        conn.execute(text("""
                            INSERT INTO quotations (é¡¹ç›®åç§°,ä¾›åº”å•†åç§°,è¯¢ä»·äºº,è®¾å¤‡ææ–™åç§°,å“ç‰Œ,æ•°é‡ç¡®è®¤,è®¾å¤‡å•ä»·,äººå·¥åŒ…å¹²å•ä»·,å¸ç§,æè¿°,å½•å…¥äºº,åœ°åŒº,è¯¢ä»·æ—¥æœŸ)
                            VALUES (:p,:s,:i,:n,:b,:q,:pr,:lp,:c,:d,:u,:reg,:dt)
                        """), {"p": pj, "s": sup, "i": inq, "n": name, "b": brand if brand is not None else "",
                               "q": qty, "pr": price if price != 0 else None,
                               "lp": labor_price if labor_price != 0 else None,
                               "c": cur, "d": desc, "u": user["username"], "reg": user["region"], "dt": str(date_inq)})
                    st.success("æ‰‹å·¥è®°å½•å·²æ·»åŠ ï¼ˆæŒ‰åŸé€»è¾‘ï¼Œå“ç‰Œä¸ºå¯é€‰ï¼‰ã€‚")
                except Exception as e:
                    st.error(f"æ·»åŠ è®°å½•å¤±è´¥ï¼š{e}")

# ============ Search / Delete (Admin) ============
if page == "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢":
    st.header("ğŸ“‹ è®¾å¤‡æŸ¥è¯¢")
    kw = st.text_input("å…³é”®è¯ï¼ˆå¤šä¸ªç©ºæ ¼åˆ†è¯ï¼‰", key="search_kw")
    search_fields = st.multiselect("æœç´¢å­—æ®µï¼ˆç•™ç©ºä¸ºé»˜è®¤ï¼‰",
                                   ["è®¾å¤‡ææ–™åç§°", "æè¿°", "å“ç‰Œ", "è§„æ ¼æˆ–å‹å·", "é¡¹ç›®åç§°", "ä¾›åº”å•†åç§°", "åœ°åŒº"],
                                   key="search_fields")
    pj_filter = st.text_input("æŒ‰é¡¹ç›®åç§°è¿‡æ»¤", key="search_pj")
    sup_filter = st.text_input("æŒ‰ä¾›åº”å•†åç§°è¿‡æ»¤", key="search_sup")
    brand_filter = st.text_input("æŒ‰å“ç‰Œè¿‡æ»¤", key="search_brand")
    cur_filter = st.selectbox("å¸ç§", ["å…¨éƒ¨","IDR","USD","RMB","SGD","MYR","THB"], index=0, key="search_cur")

    regions_options = ["å…¨éƒ¨","Singapore","Malaysia","Thailand","Indonesia","Vietnam","Philippines","Others","All"]
    if user["role"] == "admin":
        region_filter = st.selectbox("æŒ‰åœ°åŒºè¿‡æ»¤ï¼ˆç®¡ç†å‘˜ï¼‰", regions_options, index=0, key="search_region")
    else:
        st.info(f"ä»…æ˜¾ç¤ºæ‚¨æ‰€åœ¨åœ°åŒºçš„æ•°æ®ï¼š{user['region']}")
        region_filter = user["region"]

    if st.button("ğŸ” æœç´¢è®¾å¤‡", key="search_button"):
        conds = []
        params = {}
        if pj_filter:
            conds.append("LOWER(é¡¹ç›®åç§°) LIKE :pj")
            params["pj"] = f"%{pj_filter.lower()}%"
        if sup_filter:
            conds.append("LOWER(ä¾›åº”å•†åç§°) LIKE :sup")
            params["sup"] = f"%{sup_filter.lower()}%"
        if brand_filter:
            conds.append("LOWER(å“ç‰Œ) LIKE :brand")
            params["brand"] = f"%{brand_filter.lower()}%"
        if cur_filter != "å…¨éƒ¨":
            conds.append("å¸ç§ = :cur")
            params["cur"] = cur_filter
        if user["role"] != "admin":
            conds.append("åœ°åŒº = :r")
            params["r"] = user["region"]
        else:
            if region_filter and region_filter != "å…¨éƒ¨":
                conds.append("åœ°åŒº = :r")
                params["r"] = region_filter

        if kw:
            tokens = re.findall(r"\S+", kw)
            fields = search_fields if search_fields else ["è®¾å¤‡ææ–™åç§°","æè¿°","å“ç‰Œ","è§„æ ¼æˆ–å‹å·","é¡¹ç›®åç§°","ä¾›åº”å•†åç§°"]
            for i, t in enumerate(tokens):
                ors = []
                for j, f in enumerate(fields):
                    pname = f"kw_{i}_{j}"
                    ors.append(f"LOWER({f}) LIKE :{pname}")
                    params[pname] = f"%{t.lower()}%"
                conds.append("(" + " OR ".join(ors) + ")")

        sql = "SELECT rowid, * FROM quotations"
        if conds:
            sql += " WHERE " + " AND ".join(conds)

        try:
            df = pd.read_sql(sql, engine, params=params)
        except Exception as e:
            st.error(f"æŸ¥è¯¢å¤±è´¥ï¼š{e}")
            df = pd.DataFrame()

        if df.empty:
            st.info("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®°å½•ã€‚")
        else:
            safe_st_dataframe(df)
            # download
            buf = io.BytesIO()
            with pd.ExcelWriter(buf, engine="openpyxl") as writer:
                df.to_excel(writer, index=False)
            buf.seek(0)
            st.download_button("ä¸‹è½½ç»“æœ", buf, "è®¾å¤‡æŸ¥è¯¢ç»“æœ.xlsx", key="download_search")

            # Admin delete form (single form)
            if user["role"] == "admin":
                st.markdown("---")
                st.markdown("âš ï¸ ç®¡ç†å‘˜åˆ é™¤ï¼šé€‰æ‹©è®°å½•å¹¶ç¡®è®¤ã€‚")
                choices = []
                for _, row in df.iterrows():
                    rid = int(row["rowid"])
                    proj = str(row.get("é¡¹ç›®åç§°",""))[:40]
                    name = str(row.get("è®¾å¤‡ææ–™åç§°",""))[:60]
                    brand = str(row.get("å“ç‰Œ",""))[:30]
                    choices.append(f"{rid} | {proj} | {name} | {brand}")

                with st.form("admin_delete_form_final_v2", clear_on_submit=False):
                    selected = st.multiselect("é€‰ä¸­è¦åˆ é™¤çš„è®°å½•", choices, key="admin_delete_selected_v2")
                    confirm = st.checkbox("æˆ‘ç¡®è®¤åˆ é™¤æ‰€é€‰è®°å½•ï¼ˆä¸å¯æ¢å¤ï¼‰", key="admin_delete_confirm_v2")
                    submit_del = st.form_submit_button("åˆ é™¤æ‰€é€‰è®°å½•ï¼ˆç®¡ç†å‘˜ï¼‰", key="admin_delete_submit_v2")

                if submit_del:
                    if not selected:
                        st.warning("è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„è®°å½•ã€‚")
                    elif not confirm:
                        st.warning("è¯·å‹¾é€‰ç¡®è®¤æ¡†ä»¥æ‰§è¡Œåˆ é™¤ã€‚")
                    else:
                        try:
                            selected_rowids = [int(s.split("|",1)[0].strip()) for s in selected]
                        except Exception as e:
                            st.error(f"è§£ææ‰€é€‰ rowid å¤±è´¥ï¼š{e}")
                            selected_rowids = []

                        if not selected_rowids:
                            st.warning("æ— æœ‰æ•ˆ rowidï¼Œå–æ¶ˆåˆ é™¤ã€‚")
                        else:
                            placeholders = ",".join(str(int(r)) for r in selected_rowids)
                            select_verify_sql = f"SELECT rowid, é¡¹ç›®åç§°, ä¾›åº”å•†åç§°, è®¾å¤‡ææ–™åç§°, å“ç‰Œ FROM quotations WHERE rowid IN ({placeholders})"
                            try:
                                matched_df = pd.read_sql(select_verify_sql, engine)
                            except Exception as e:
                                st.error(f"åŒ¹é…æŸ¥è¯¢å¤±è´¥ï¼š{e}")
                                matched_df = pd.DataFrame()

                            if matched_df.empty:
                                st.warning("æœªåœ¨æ•°æ®åº“ä¸­åŒ¹é…åˆ°æ‰€é€‰ rowidï¼Œå–æ¶ˆåˆ é™¤ã€‚")
                                st.write("æ‰§è¡Œçš„ SELECT SQLï¼š", select_verify_sql)
                            else:
                                st.markdown("ä»¥ä¸‹ä¸ºå°†è¢«åˆ é™¤çš„åŒ¹é…è®°å½•ï¼Œè¯·æ ¸å¯¹ï¼š")
                                safe_st_dataframe(matched_df)

                                # Try archive first (ignore archive errors)
                                try:
                                    with engine.begin() as conn:
                                        conn.execute(text(f"""
                                            INSERT INTO deleted_quotations
                                            SELECT rowid AS original_rowid, åºå·, è®¾å¤‡ææ–™åç§°, è§„æ ¼æˆ–å‹å·, æè¿°, å“ç‰Œ, å•ä½, æ•°é‡ç¡®è®¤,
                                                   æŠ¥ä»·å“ç‰Œ, å‹å·, è®¾å¤‡å•ä»·, è®¾å¤‡å°è®¡, äººå·¥åŒ…å¹²å•ä»·, äººå·¥åŒ…å¹²å°è®¡, ç»¼åˆå•ä»·æ±‡æ€»,
                                                   å¸ç§, åŸå‚å“ç‰Œç»´ä¿æœŸé™, è´§æœŸ, å¤‡æ³¨, è¯¢ä»·äºº, é¡¹ç›®åç§°, ä¾›åº”å•†åç§°, è¯¢ä»·æ—¥æœŸ, å½•å…¥äºº, åœ°åŒº,
                                                   CURRENT_TIMESTAMP AS deleted_at, :user AS deleted_by
                                            FROM quotations WHERE rowid IN ({placeholders})
                                        """), {"user": user["username"]})
                                    st.write("å·²å°è¯•å½’æ¡£ï¼ˆè‹¥è¡¨ä¸å­˜åœ¨åˆ™å¿½ç•¥ï¼‰ã€‚")
                                except Exception as e_arch:
                                    st.warning(f"å½’æ¡£å¼‚å¸¸ï¼ˆå·²å¿½ç•¥ï¼‰ï¼š{e_arch}")

                                # Execute DELETE and check rowcount
                                delete_sql = f"DELETE FROM quotations WHERE rowid IN ({placeholders})"
                                try:
                                    with engine.begin() as conn:
                                        res = conn.execute(text(delete_sql))
                                        deleted_count = getattr(res, "rowcount", None)
                                    if deleted_count is None:
                                        st.info("åˆ é™¤æ‰§è¡Œï¼Œä½†æœªè·å– rowcountï¼Œè¯·æŸ¥è¯¢ç¡®è®¤ã€‚")
                                    elif deleted_count == 0:
                                        st.warning("DELETE æ‰§è¡ŒæˆåŠŸä½†æœªåˆ é™¤ä»»ä½•è¡Œï¼ˆrowcount=0ï¼‰ã€‚")
                                    else:
                                        st.success(f"å·²åˆ é™¤ {deleted_count} æ¡è®°å½•ã€‚")
                                except Exception as e_del:
                                    st.error(f"æ‰§è¡Œ DELETE æ—¶å¼‚å¸¸ï¼š{e_del}")

                                # Verify after deletion
                                try:
                                    after_df = pd.read_sql(select_verify_sql, engine)
                                    if after_df.empty:
                                        st.info("åˆ é™¤åå¤æŸ¥æœªæ‰¾åˆ°è¿™äº›è®°å½•ï¼ˆåˆ é™¤æˆåŠŸï¼‰ã€‚")
                                    else:
                                        st.warning("åˆ é™¤åä»æŸ¥è¯¢åˆ°éƒ¨åˆ†è®°å½•ï¼ˆè¯·æ£€æŸ¥ï¼‰ï¼š")
                                        safe_st_dataframe(after_df)
                                except Exception as e_after:
                                    st.warning(f"åˆ é™¤åå¤æ ¸å¤±è´¥ï¼š{e_after}")

                                safe_rerun()
            else:
                st.info("ä»…ç®¡ç†å‘˜å¯åˆ é™¤è®°å½•ã€‚")

# ============ Misc costs page ============
elif page == "ğŸ’° æ‚è´¹æŸ¥è¯¢":
    st.header("ğŸ’° æ‚è´¹æŸ¥è¯¢")
    pj2 = st.text_input("æŒ‰é¡¹ç›®åç§°è¿‡æ»¤", key="misc_pj")
    if st.button("ğŸ” æœç´¢æ‚è´¹", key="misc_search"):
        params = {"pj": f"%{pj2.lower()}%"}
        sql = "SELECT * FROM misc_costs WHERE LOWER(é¡¹ç›®åç§°) LIKE :pj"
        if user["role"] != "admin":
            sql += " AND åœ°åŒº = :r"
            params["r"] = user["region"]
        df2 = pd.read_sql(sql, engine, params=params)
        safe_st_dataframe(df2)
        if not df2.empty:
            buf2 = io.BytesIO()
            with pd.ExcelWriter(buf2, engine="openpyxl") as writer:
                df2.to_excel(writer, index=False)
            buf2.seek(0)
            st.download_button("ä¸‹è½½æ‚è´¹ç»“æœ", buf2, "misc_costs.xlsx", key="download_misc")

# ============ Admin page ============
elif page == "ğŸ‘‘ ç®¡ç†å‘˜åå°" and user["role"] == "admin":
    st.header("ğŸ‘‘ ç®¡ç†åå°")
    users_df = pd.read_sql("SELECT username, role, region FROM users", engine)
    safe_st_dataframe(users_df)
