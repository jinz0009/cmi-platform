# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from sqlalchemy import create_engine, text
import hashlib, io, re, math

# ============ åŸºç¡€é…ç½® ============
st.set_page_config(page_title="CMI è¯¢ä»·å½•å…¥ä¸æŸ¥è¯¢å¹³å°", layout="wide")

# Streamlit Cloud æ¯æ¬¡å¯åŠ¨ä¼šé‡ç½®å†…å­˜ï¼Œå› æ­¤ä½¿ç”¨æœ¬åœ° SQLiteï¼ˆä¸´æ—¶å­˜å‚¨ï¼‰
engine = create_engine("sqlite:///quotation.db")

# ============ åˆå§‹åŒ–æ•°æ®åº“ ============
with engine.begin() as conn:
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT UNIQUE,
        password TEXT,
        role TEXT CHECK(role IN ('admin','user')),
        region TEXT
    )
    """))
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS quotations (
        åºå· TEXT,
        è®¾å¤‡ææ–™åç§° TEXT NOT NULL,
        è§„æ ¼æˆ–å‹å· TEXT,
        æè¿° TEXT,
        å“ç‰Œ TEXT NOT NULL,
        å•ä½ TEXT,
        æ•°é‡ç¡®è®¤ REAL,
        æŠ¥ä»·å“ç‰Œ TEXT,
        å‹å· TEXT,
        è®¾å¤‡å•ä»· REAL,
        è®¾å¤‡å°è®¡ REAL,
        äººå·¥åŒ…å¹²å•ä»· REAL,
        äººå·¥åŒ…å¹²å°è®¡ REAL,
        ç»¼åˆå•ä»·æ±‡æ€» REAL,
        å¸ç§ TEXT,
        åŸå‚å“ç‰Œç»´ä¿æœŸé™ TEXT,
        è´§æœŸ TEXT,
        å¤‡æ³¨ TEXT,
        è¯¢ä»·äºº TEXT,
        é¡¹ç›®åç§° TEXT,
        ä¾›åº”å•†åç§° TEXT,
        è¯¢ä»·æ—¥æœŸ TEXT,
        å½•å…¥äºº TEXT,
        åœ°åŒº TEXT
    )
    """))
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS misc_costs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        é¡¹ç›®åç§° TEXT,
        æ‚è´¹ç±»ç›® TEXT,
        é‡‘é¢ REAL,
        å¸ç§ TEXT,
        å½•å…¥äºº TEXT,
        åœ°åŒº TEXT
    )
    """))
    conn.execute(text("""
    INSERT OR IGNORE INTO users (username, password, role, region)
    VALUES ('admin', :pw, 'admin', 'All')
    """), {"pw": hashlib.sha256("admin123".encode()).hexdigest()})

# ============ å¸®åŠ©ï¼šè¡¨å¤´æ˜ å°„å­—å…¸ï¼ˆå¯æ‰©å±•ï¼‰ ============
HEADER_SYNONYMS = {
    "åºå·": "åºå·", "no": "åºå·", "index": "åºå·",
    "è®¾å¤‡ææ–™åç§°": "è®¾å¤‡ææ–™åç§°", "è®¾å¤‡åç§°": "è®¾å¤‡ææ–™åç§°",
    "material": "è®¾å¤‡ææ–™åç§°", "material name": "è®¾å¤‡ææ–™åç§°",
    "item": "è®¾å¤‡ææ–™åç§°", "name": "è®¾å¤‡ææ–™åç§°",
    "è§„æ ¼æˆ–å‹å·": "è§„æ ¼æˆ–å‹å·", "è§„æ ¼": "è§„æ ¼æˆ–å‹å·", "model": "è§„æ ¼æˆ–å‹å·", "spec": "è§„æ ¼æˆ–å‹å·",
    "æè¿°": "æè¿°", "description": "æè¿°",
    "å“ç‰Œ": "å“ç‰Œ", "brand": "å“ç‰Œ",
    "å•ä½": "å•ä½", "unit": "å•ä½",
    "æ•°é‡ç¡®è®¤": "æ•°é‡ç¡®è®¤", "æ•°é‡": "æ•°é‡ç¡®è®¤", "qty": "æ•°é‡ç¡®è®¤", "quantity": "æ•°é‡ç¡®è®¤",
    "æŠ¥ä»·å“ç‰Œ": "æŠ¥ä»·å“ç‰Œ", "æŠ¥ä»·": "æŠ¥ä»·å“ç‰Œ",
    "å‹å·": "å‹å·",
    "è®¾å¤‡å•ä»·": "è®¾å¤‡å•ä»·", "å•ä»·": "è®¾å¤‡å•ä»·", "price": "è®¾å¤‡å•ä»·", "unit price": "è®¾å¤‡å•ä»·",
    "è®¾å¤‡å°è®¡": "è®¾å¤‡å°è®¡", "subtotal": "è®¾å¤‡å°è®¡",
    "äººå·¥åŒ…å¹²å•ä»·": "äººå·¥åŒ…å¹²å•ä»·", "äººå·¥åŒ…å¹²å°è®¡": "äººå·¥åŒ…å¹²å°è®¡", "ç»¼åˆå•ä»·æ±‡æ€»": "ç»¼åˆå•ä»·æ±‡æ€»",
    "å¸ç§": "å¸ç§", "currency": "å¸ç§",
    "åŸå‚å“ç‰Œç»´ä¿æœŸé™": "åŸå‚å“ç‰Œç»´ä¿æœŸé™", "è´§æœŸ": "è´§æœŸ",
    "å¤‡æ³¨": "å¤‡æ³¨", "remark": "å¤‡æ³¨", "notes": "å¤‡æ³¨",
    "è¯¢ä»·äºº": "è¯¢ä»·äºº", "enquirer": "è¯¢ä»·äºº", "inquirer": "è¯¢ä»·äºº",
    "é¡¹ç›®åç§°": "é¡¹ç›®åç§°", "project": "é¡¹ç›®åç§°", "project name": "é¡¹ç›®åç§°",
    "ä¾›åº”å•†åç§°": "ä¾›åº”å•†åç§°", "supplier": "ä¾›åº”å•†åç§°", "vendor": "ä¾›åº”å•†åç§°",
    "è¯¢ä»·æ—¥æœŸ": "è¯¢ä»·æ—¥æœŸ", "date": "è¯¢ä»·æ—¥æœŸ",
    "å½•å…¥äºº": "å½•å…¥äºº", "åœ°åŒº": "åœ°åŒº",
    # å¸¦å¸ç§/æ‹¬å·çš„å¸¸è§å†™æ³•ï¼ˆç¤ºä¾‹ï¼‰
    "è®¾å¤‡å•ä»·ï¼ˆidrï¼‰": "è®¾å¤‡å•ä»·", "è®¾å¤‡å•ä»·(idr)": "è®¾å¤‡å•ä»·", "è®¾å¤‡å•ä»·ï¼ˆrmbï¼‰": "è®¾å¤‡å•ä»·",
    "è®¾å¤‡å•ä»·(rmb)": "è®¾å¤‡å•ä»·", "è®¾å¤‡å°è®¡ï¼ˆidrï¼‰": "è®¾å¤‡å°è®¡", "è®¾å¤‡å°è®¡(idr)": "è®¾å¤‡å°è®¡",
    "è®¾å¤‡å°è®¡ï¼ˆrmbï¼‰": "è®¾å¤‡å°è®¡", "è®¾å¤‡å°è®¡(rmb)": "è®¾å¤‡å°è®¡",
    "äººå·¥åŒ…å¹²å•ä»·ï¼ˆidrï¼‰": "äººå·¥åŒ…å¹²å•ä»·", "äººå·¥åŒ…å¹²å•ä»·(idr)": "äººå·¥åŒ…å¹²å•ä»·",
    "äººå·¥åŒ…å¹²å°è®¡ï¼ˆidrï¼‰": "äººå·¥åŒ…å¹²å°è®¡", "äººå·¥åŒ…å¹²å°è®¡(idr)": "äººå·¥åŒ…å¹²å°è®¡",
    "ç»¼åˆå•ä»·æ±‡æ€»ï¼ˆidrï¼‰": "ç»¼åˆå•ä»·æ±‡æ€»", "ç»¼åˆå•ä»·æ±‡æ€»(idr)": "ç»¼åˆå•ä»·æ±‡æ€»",
    "price (idr)": "è®¾å¤‡å•ä»·", "subtotal (idr)": "è®¾å¤‡å°è®¡",
}

DB_COLUMNS = [
    "åºå·","è®¾å¤‡ææ–™åç§°","è§„æ ¼æˆ–å‹å·","æè¿°","å“ç‰Œ","å•ä½","æ•°é‡ç¡®è®¤",
    "æŠ¥ä»·å“ç‰Œ","å‹å·","è®¾å¤‡å•ä»·","è®¾å¤‡å°è®¡","äººå·¥åŒ…å¹²å•ä»·","äººå·¥åŒ…å¹²å°è®¡",
    "ç»¼åˆå•ä»·æ±‡æ€»","å¸ç§","åŸå‚å“ç‰Œç»´ä¿æœŸé™","è´§æœŸ","å¤‡æ³¨",
    "è¯¢ä»·äºº","é¡¹ç›®åç§°","ä¾›åº”å•†åç§°","è¯¢ä»·æ—¥æœŸ","å½•å…¥äºº","åœ°åŒº"
]

def auto_map_header(orig_header: str):
    if orig_header is None:
        return None
    h = str(orig_header).strip().lower()
    for k, v in HEADER_SYNONYMS.items():
        if h == k.lower():
            return v
    h_norm = re.sub(r"[\s\-\_ï¼š:ï¼ˆï¼‰()]+", " ", h).strip()
    for k, v in HEADER_SYNONYMS.items():
        k_norm = re.sub(r"[\s\-\_ï¼š:ï¼ˆï¼‰()]+", " ", k.lower()).strip()
        if h_norm == k_norm:
            return v
    for k, v in HEADER_SYNONYMS.items():
        if k.lower() in h or h in k.lower():
            return v
    words = re.findall(r"[a-zA-Z\u4e00-\u9fff]+", h)
    for w in words:
        for k, v in HEADER_SYNONYMS.items():
            if w == k.lower():
                return v
    return None

def detect_header_from_preview(df_preview: pd.DataFrame, max_header_rows=2, max_search_rows=8):
    nrows = df_preview.shape[0]
    ncols = df_preview.shape[1]
    search_rows = min(max_search_rows, nrows)
    best = {"score": -1, "header": None, "row": None, "rows_used": 1}
    for start in range(search_rows):
        for rows_used in range(1, max_header_rows + 1):
            if start + rows_used > nrows:
                continue
            cand = []
            for col in range(ncols):
                parts = []
                for r in range(start, start + rows_used):
                    cell = df_preview.iat[r, col]
                    if pd.isna(cell):
                        continue
                    s = str(cell).strip()
                    if s:
                        parts.append(s)
                header_text = " ".join(parts).strip()
                cand.append(header_text)
            mapped_count = 0
            nonempty_count = sum(1 for x in cand if x)
            for h in cand:
                if h and auto_map_header(h):
                    mapped_count += 1
            score = mapped_count + 0.5 * nonempty_count
            if score > best["score"]:
                best = {"score": score, "header": cand, "row": start, "rows_used": rows_used, "mapped": mapped_count, "nonempty": nonempty_count}
    if best["header"] is not None:
        if best["mapped"] >= 2 or (best["nonempty"] > 0 and best["mapped"] / best["nonempty"] >= 0.3):
            return best["header"], best["row"] + best["rows_used"] - 1
    return None, None

# è§„èŒƒåŒ–ç”¨äºæ˜¾ç¤ºçš„ DataFrameï¼ˆé¿å… ArrowTypeErrorï¼‰
def normalize_for_display(df: pd.DataFrame) -> pd.DataFrame:
    df_disp = df.copy()
    for col in df_disp.columns:
        try:
            ser = df_disp[col]
            if ser.dtype != "object":
                # keep numeric/datetime as-is (usually safe)
                continue
            non_null = ser.dropna()
            if non_null.empty:
                df_disp[col] = ser.where(ser.notna(), "").astype(str)
                continue
            has_bytes = any(isinstance(x, (bytes, bytearray, memoryview)) for x in non_null)
            types_seen = {type(x) for x in non_null}
            multiple_types = len(types_seen) > 1
            if has_bytes or multiple_types:
                df_disp[col] = ser.where(ser.notna(), None).apply(lambda x: "" if x is None else str(x))
            else:
                df_disp[col] = ser.where(ser.notna(), None).apply(lambda x: "" if x is None else x)
        except Exception:
            df_disp[col] = df_disp[col].where(df_disp[col].notna(), None).apply(lambda x: "" if x is None else str(x))
    return df_disp

# å®‰å…¨æ˜¾ç¤º DataFrameï¼ˆä¿®å¤ height=None é—®é¢˜å¹¶åšé™çº§ï¼‰
def safe_st_dataframe(df: pd.DataFrame, height: int | None = None):
    df_disp = normalize_for_display(df)
    try:
        if height is None:
            st.dataframe(df_disp)
        else:
            st.dataframe(df_disp, height=height)
    except Exception:
        df2 = df_disp.copy()
        for col in df2.columns:
            try:
                df2[col] = df2[col].where(df2[col].notna(), None).apply(lambda x: "" if x is None else str(x))
            except Exception:
                df2[col] = df2[col].astype(str).fillna("")
        if height is None:
            st.dataframe(df2)
        else:
            st.dataframe(df2, height=height)

# ============ ç™»å½•æ³¨å†Œé€»è¾‘ ============
def login():
    st.subheader("ğŸ” ç”¨æˆ·ç™»å½•")
    username = st.text_input("ç”¨æˆ·å")
    password = st.text_input("å¯†ç ", type="password")
    if st.button("ç™»å½•"):
        pw_hash = hashlib.sha256(password.encode()).hexdigest()
        with engine.begin() as conn:
            user = conn.execute(
                text("SELECT * FROM users WHERE username=:u AND password=:p"),
                {"u": username, "p": pw_hash}
            ).fetchone()
        if user:
            st.session_state["user"] = {"username": username, "role": user.role, "region": user.region}
            st.success(f"âœ… ç™»å½•æˆåŠŸï¼æ¬¢è¿ {username}ï¼ˆ{user.region}ï¼‰")
            st.rerun()
        else:
            st.error("âŒ ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

def register():
    st.subheader("ğŸ§¾ æ³¨å†Œæ–°ç”¨æˆ·")
    username = st.text_input("æ–°ç”¨æˆ·å")
    password = st.text_input("æ–°å¯†ç ", type="password")
    region = st.selectbox("æ‰€å±åœ°åŒº", ["Singapore","Malaysia","Thailand","Indonesia","Vietnam","Philippines","Others"])
    if st.button("æ³¨å†Œ"):
        if not username or not password:
            st.warning("è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ")
        else:
            pw_hash = hashlib.sha256(password.encode()).hexdigest()
            try:
                with engine.begin() as conn:
                    conn.execute(
                        text("INSERT INTO users (username, password, role, region) VALUES (:u, :p, 'user', :r)"),
                        {"u": username, "p": pw_hash, "r": region}
                    )
                st.success("âœ… æ³¨å†ŒæˆåŠŸï¼Œè¯·è¿”å›ç™»å½•é¡µã€‚")
            except Exception:
                st.error("âŒ ç”¨æˆ·åå·²å­˜åœ¨")

def logout():
    st.session_state.clear()
    st.rerun()

# ============ é¡µé¢åˆ‡æ¢ ============
if "user" not in st.session_state:
    tab = st.tabs(["ğŸ”‘ ç™»å½•", "ğŸ§¾ æ³¨å†Œ"])
    with tab[0]:
        login()
    with tab[1]:
        register()
    st.stop()

user = st.session_state["user"]
st.sidebar.markdown(f"ğŸ‘¤ **{user['username']}**  \nğŸ¢ åœ°åŒºï¼š{user['region']}  \nğŸ”‘ è§’è‰²ï¼š{user['role']}")
if st.sidebar.button("ğŸšª é€€å‡ºç™»å½•"):
    logout()

page = st.sidebar.radio("å¯¼èˆª", ["ğŸ  ä¸»é¡µé¢", "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢", "ğŸ’° æ‚è´¹æŸ¥è¯¢", "ğŸ‘‘ ç®¡ç†å‘˜åå°"] if user["role"]=="admin" else ["ğŸ  ä¸»é¡µé¢", "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢", "ğŸ’° æ‚è´¹æŸ¥è¯¢"])

# ============ ä¸»é¡µé¢ï¼šå½•å…¥ ============
if page == "ğŸ  ä¸»é¡µé¢":
    st.title("ğŸ“Š è¯¢ä»·å½•å…¥ä¸æŸ¥è¯¢å¹³å°")

    st.header("ğŸ“‚ Excel æ‰¹é‡å½•å…¥ï¼ˆæ™ºèƒ½è¡¨å¤´æ˜ å°„ï¼‰")
    st.caption("ç³»ç»Ÿä¼šå°è¯•è¯†åˆ«ä¸Šä¼ æ–‡ä»¶çš„è¡¨å¤´ï¼ˆæ”¯æŒå‰å‡ è¡Œä¸ºåˆå¹¶å•å…ƒæ ¼æˆ–æ ‡é¢˜ï¼‰ï¼Œå¹¶ç»™å‡ºå»ºè®®æ˜ å°„ã€‚ç³»ç»Ÿä¼šå…ˆè‡ªåŠ¨å¯¹åº”ä¸€ç‰ˆå»ºè®®ï¼Œä½ å¯ä»¥æŒ‰åˆ—ä¿®æ”¹å¹¶çœ‹åˆ°å“ªäº›ç›®æ ‡åˆ—æœªè¢«æä¾›æˆ–æ— å€¼ã€‚")

    template = pd.DataFrame(columns=[c for c in DB_COLUMNS if c not in ("å½•å…¥äºº","åœ°åŒº")])
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as w:
        template.to_excel(w, index=False)
    buf.seek(0)
    st.download_button("ğŸ“¥ ä¸‹è½½æ¨¡æ¿", buf, "quotation_template.xlsx")

    uploaded = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶ï¼ˆ.xlsxï¼‰", type=["xlsx"])
    if uploaded:
        try:
            preview = pd.read_excel(uploaded, header=None, nrows=50, dtype=object)
        except Exception as e:
            st.error(f"è¯»å– Excel é¢„è§ˆå¤±è´¥ï¼š{e}")
            preview = None

        if preview is not None:
            st.markdown("**ç”¨äºè¯†åˆ«è¡¨å¤´çš„å‰å‡ è¡Œé¢„è§ˆï¼ˆä»…å±•ç¤ºï¼‰ï¼š**")
            safe_st_dataframe(preview.head(10))

            header_names, header_row_index = detect_header_from_preview(preview, max_header_rows=2, max_search_rows=8)
            raw_df_full = pd.read_excel(uploaded, header=None, dtype=object)

            if header_names is None:
                st.info("æœªèƒ½è‡ªåŠ¨è¯†åˆ«è¡¨å¤´ï¼Œè¯·æ‰‹åŠ¨æ˜ å°„ï¼ˆç³»ç»Ÿå·²æŠŠç¬¬ä¸€è¡Œä½œä¸ºå€™é€‰ï¼‰ã€‚")
                header_row_index = 0
                header_names = [str(x) if not pd.isna(x) else "" for x in raw_df_full.iloc[0].tolist()]
            else:
                st.success(f"å·²æ£€æµ‹åˆ°è¡¨å¤´ï¼ˆç»“æŸäºç¬¬ {header_row_index+1} è¡Œï¼‰ï¼Œç³»ç»Ÿå·²ç”Ÿæˆå»ºè®®æ˜ å°„ï¼š")
                st.write(header_names)

            header_names = [str(x).strip() if (x is not None and not pd.isna(x)) else "" for x in header_names]

            data_df = raw_df_full.iloc[header_row_index+1 : ].copy().reset_index(drop=True)
            if len(header_names) < data_df.shape[1]:
                header_names += [f"Unnamed_{i}" for i in range(len(header_names), data_df.shape[1])]
            elif len(header_names) > data_df.shape[1]:
                header_names = header_names[:data_df.shape[1]]

            data_df.columns = header_names

            st.markdown("**æ£€æµ‹åˆ°çš„åŸå§‹è¡¨å¤´ï¼ˆç”¨äºæ˜ å°„ï¼Œç³»ç»Ÿå·²å°è¯•è‡ªåŠ¨å¯¹åº”ä¸€ç‰ˆå»ºè®®ï¼‰ï¼š**")
            st.write(list(data_df.columns))

            mapping_targets = ["Ignore"] + [c for c in DB_COLUMNS if c not in ("å½•å…¥äºº","åœ°åŒº")]

            auto_defaults = {}
            for col in data_df.columns:
                auto_val = auto_map_header(col)
                if auto_val and auto_val in mapping_targets:
                    auto_defaults[col] = auto_val
                else:
                    auto_defaults[col] = "Ignore"

            st.markdown("ç³»ç»Ÿå·²ä¸ºæ¯ä¸€åˆ—ç”Ÿæˆå»ºè®®æ˜ å°„ï¼ˆä½ å¯ä»¥ç›´æ¥ç‚¹å‡»â€œåº”ç”¨æ˜ å°„å¹¶é¢„è§ˆâ€ æˆ– ä¿®æ”¹ä»»æ„ä¸‹æ‹‰å†æäº¤ï¼‰ã€‚")

            mapped_choices = {}
            with st.form("mapping_form"):
                cols_left, cols_right = st.columns(2)
                for i, col in enumerate(data_df.columns):
                    default = auto_defaults.get(col, "Ignore")
                    container = cols_left if i % 2 == 0 else cols_right
                    sel = container.selectbox(f"æºåˆ—: {col}", mapping_targets,
                                              index = mapping_targets.index(default) if default in mapping_targets else 0,
                                              key=f"map_{i}")
                    mapped_choices[col] = sel
                submitted = st.form_submit_button("åº”ç”¨æ˜ å°„å¹¶é¢„è§ˆ")

            if submitted:
                target_sources = {}
                for src, tgt in mapped_choices.items():
                    if tgt != "Ignore":
                        target_sources.setdefault(tgt, []).append(src)

                unmapped_targets = [t for t in DB_COLUMNS if t not in ("å½•å…¥äºº","åœ°åŒº") and t not in target_sources.keys()]

                dup_targets = {t: s for t, s in target_sources.items() if len(s) > 1}
                if dup_targets:
                    dup_messages = []
                    for t, srcs in dup_targets.items():
                        dup_messages.append(f"ç›®æ ‡åˆ— '{t}' è¢«å¤šä¸ªæºåˆ—æ˜ å°„: {', '.join(srcs)}")
                    st.error("æ£€æµ‹åˆ°å¤šä¸ªæºåˆ—æ˜ å°„åŒä¸€ç›®æ ‡åˆ—ï¼ˆè¿™æ˜¯ä¸å…è®¸çš„ï¼‰ã€‚è¯·åœ¨æ˜ å°„ä¸­åªä¸ºæ¯ä¸ªç›®æ ‡é€‰æ‹©ä¸€ä¸ªæºåˆ—ã€‚\n\n" + "\n".join(dup_messages))
                    st.stop()

                mapped_but_empty = []
                for tgt, srcs in target_sources.items():
                    has_value = False
                    for s in srcs:
                        if s in data_df.columns:
                            col_series = data_df[s].astype(object).where(~data_df[s].astype(str).str.strip().isin(["", "nan", "none"]), pd.NA)
                            if col_series.dropna().size > 0:
                                has_value = True
                                break
                    if not has_value:
                        mapped_but_empty.append(tgt)

                rename_dict = {orig: mapped for orig, mapped in mapped_choices.items() if mapped != "Ignore"}
                df_mapped = data_df.rename(columns=rename_dict).copy()
                for c in DB_COLUMNS:
                    if c not in df_mapped.columns:
                        df_mapped[c] = pd.NA
                df_mapped["å½•å…¥äºº"] = user["username"]
                df_mapped["åœ°åŒº"] = user["region"]
                df_for_db = df_mapped[DB_COLUMNS]

                st.markdown("**æ˜ å°„åé¢„è§ˆï¼ˆå‰ 10 è¡Œï¼‰ï¼š**")
                safe_st_dataframe(df_for_db.head(10))

                # å…¨å±€ä¿¡æ¯ï¼šåœ¨å•ç‹¬è¡¨å•å†…æäº¤ï¼Œé¿å…åªè¾“å…¥ä¸€é¡¹å°±ç»§ç»­
                st.markdown("è¯·å…ˆå¡«å†™ä»¥ä¸‹å…¨å±€å¿…å¡«ä¿¡æ¯ï¼ˆä¼šåº”ç”¨åˆ°æ‰€æœ‰å¯¼å…¥è®°å½•ï¼‰ï¼Œå¡«å†™å®Œåç‚¹å‡»â€œåº”ç”¨å…¨å±€å¹¶ç»§ç»­æ ¡éªŒâ€ï¼š")
                with st.form("global_form"):
                    col_a, col_b, col_c, col_d = st.columns(4)
                    global_project = col_a.text_input("é¡¹ç›®åç§°", key="bulk_project")
                    global_supplier = col_b.text_input("ä¾›åº”å•†åç§°", key="bulk_supplier")
                    global_enquirer = col_c.text_input("è¯¢ä»·äºº", key="bulk_enquirer")
                    global_date = col_d.date_input("è¯¢ä»·æ—¥æœŸ", key="bulk_date")
                    apply_global = st.form_submit_button("åº”ç”¨å…¨å±€å¹¶ç»§ç»­æ ¡éªŒ")

                if not apply_global:
                    st.info("è¯·å¡«å†™å…¨å±€å¿…å¡«ä¿¡æ¯å¹¶ç‚¹å‡»â€œåº”ç”¨å…¨å±€å¹¶ç»§ç»­æ ¡éªŒâ€ä»¥ç»§ç»­ã€‚")
                    st.stop()

                if not (global_project and global_supplier and global_enquirer and global_date):
                    st.error("å¿…é¡»å¡«å†™ï¼šé¡¹ç›®åç§°ã€ä¾›åº”å•†åç§°ã€è¯¢ä»·äººå’Œè¯¢ä»·æ—¥æœŸï¼Œæ‰èƒ½ç»§ç»­å¯¼å…¥ã€‚")
                    st.stop()

                # å°†å››ä¸ªå…¨å±€å­—æ®µå†™å…¥æ‰€æœ‰è¡Œï¼ˆè¦†ç›–æˆ–æ”¹ä¸º fillna è¡Œä¸ºå¯æŒ‰éœ€åˆ‡æ¢ï¼‰
                df_final = df_for_db.copy()
                df_final["é¡¹ç›®åç§°"] = str(global_project)
                df_final["ä¾›åº”å•†åç§°"] = str(global_supplier)
                df_final["è¯¢ä»·äºº"] = str(global_enquirer)
                df_final["è¯¢ä»·æ—¥æœŸ"] = str(global_date)

                overall_required = ["é¡¹ç›®åç§°","ä¾›åº”å•†åç§°","è¯¢ä»·äºº","è®¾å¤‡ææ–™åç§°","å“ç‰Œ","è®¾å¤‡å•ä»·","å¸ç§","è¯¢ä»·æ—¥æœŸ"]

                def normalize_cell(x):
                    if pd.isna(x):
                        return None
                    s = str(x).strip()
                    if s.lower() in ("", "nan", "none"):
                        return None
                    return s

                # ä½¿ç”¨è§„èŒƒåŒ–æ˜¾ç¤ºå‰¯æœ¬è¿›è¡Œå±•ç¤ºå’Œé—®é¢˜è¡Œé«˜äº®ï¼Œä½†ä¸šåŠ¡æ ¡éªŒåŸºäº normalize_cell åˆ¤ç©º
                df_final_disp = normalize_for_display(df_final)
                check_df = df_final.applymap(normalize_cell)[overall_required]
                rows_missing_mask = check_df.isna().any(axis=1)
                if rows_missing_mask.any():
                    bad = df_final_disp[rows_missing_mask]
                    st.error(f"æ£€æµ‹åˆ°éƒ¨åˆ†è®°å½•ç¼ºå°‘æ€»ä½“å¿…å¡«å­—æ®µï¼ˆ{', '.join(overall_required)} ä¸­è‡³å°‘ä¸€é¡¹ï¼‰ï¼šå…± {len(bad)} æ¡è®°å½•æœ‰ç¼ºé¡¹ï¼Œå·²ä¸­æ­¢å¯¼å…¥ã€‚è¯·æ£€æŸ¥æºæ•°æ®æˆ–è¡¥å…¨åå†å¯¼å…¥ã€‚")
                    safe_st_dataframe(bad.head(20))
                    st.stop()

                st.markdown("**é¢„å¤‡å¯¼å…¥çš„æœ€ç»ˆé¢„è§ˆï¼ˆå‰ 10 è¡Œï¼‰ï¼š**")
                safe_st_dataframe(df_final_disp.head(10))

                if st.button("âœ… ç¡®è®¤å¹¶å¯¼å…¥è¿™äº›è®°å½•"):
                    try:
                        df_to_store = df_final.dropna(how="all").drop_duplicates().reset_index(drop=True)
                        final_check = df_to_store[["è®¾å¤‡ææ–™åç§°","å“ç‰Œ","è®¾å¤‡å•ä»·","å¸ç§"]].applymap(normalize_cell)
                        empty_rows_mask = final_check.isna().any(axis=1)
                        if empty_rows_mask.any():
                            bad2 = normalize_for_display(df_to_store[empty_rows_mask])
                            st.error("æ£€æµ‹åˆ°éƒ¨åˆ†è®°å½•åœ¨ä¸šåŠ¡å¿…å¡«å­—æ®µï¼ˆè®¾å¤‡ææ–™åç§°ã€å“ç‰Œã€è®¾å¤‡å•ä»·ã€å¸ç§ï¼‰ä»ä¸ºç©ºï¼Œå·²ä¸­æ­¢å¯¼å…¥ã€‚è¯·æ£€æŸ¥æºæ–‡ä»¶æˆ–æ‰‹å·¥è¡¥å…¨åå†å¯¼å…¥ã€‚")
                            safe_st_dataframe(bad2.head(20))
                        else:
                            with engine.begin() as conn:
                                df_to_store.to_sql("quotations", conn, if_exists="append", index=False)
                            st.success(f"âœ… å¯¼å…¥æˆåŠŸï¼Œå…± {len(df_to_store)} æ¡è®°å½•ã€‚")
                    except Exception as e:
                        st.error(f"å¯¼å…¥å¤±è´¥ï¼š{e}")

    # 2ï¸âƒ£ æ‰‹å·¥å½•å…¥
    st.header("âœï¸ è®¾å¤‡æ‰‹å·¥å½•å…¥")
    with st.form("device_form"):
        col1, col2, col3 = st.columns(3)
        pj = col1.text_input("é¡¹ç›®åç§°")
        sup = col2.text_input("ä¾›åº”å•†åç§°")
        inq = col3.text_input("è¯¢ä»·äºº")
        name = st.text_input("è®¾å¤‡ææ–™åç§°")
        brand = st.text_input("å“ç‰Œ")
        qty = st.number_input("æ•°é‡ç¡®è®¤", min_value=0.0)
        price = st.number_input("è®¾å¤‡å•ä»·", min_value=0.0)
        cur = st.selectbox("å¸ç§", ["IDR","USD","RMB","SGD","MYR","THB"])
        desc = st.text_area("æè¿°ï¼ˆå¯é€‰ï¼‰")
        remark = st.text_area("å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰")
        date = st.date_input("è¯¢ä»·æ—¥æœŸ")
        ok = st.form_submit_button("â• æ·»åŠ è®°å½•")
    if ok:
        if not (pj and sup and inq and name and brand):
            st.error("âŒ å¿…å¡«é¡¹ä¸èƒ½ä¸ºç©º")
        else:
            with engine.begin() as conn:
                conn.execute(text("""
                INSERT INTO quotations (é¡¹ç›®åç§°,ä¾›åº”å•†åç§°,è¯¢ä»·äºº,è®¾å¤‡ææ–™åç§°,å“ç‰Œ,æ•°é‡ç¡®è®¤,
                è®¾å¤‡å•ä»·,å¸ç§,æè¿°,å¤‡æ³¨,è¯¢ä»·æ—¥æœŸ,å½•å…¥äºº,åœ°åŒº)
                VALUES (:p,:s,:i,:n,:b,:q,:pr,:c,:d,:r,:dt,:u,:reg)
                """), {"p": pj,"s": sup,"i": inq,"n": name,"b": brand,"q": qty,"pr": price,"c": cur,
                        "d": desc,"r": remark,"dt": str(date),"u": user["username"],"reg": user["region"]})
            st.success("âœ… å·²æ·»åŠ è®°å½•ã€‚")

    # 3ï¸âƒ£ æ‚è´¹å½•å…¥
    st.header("ğŸ’° æ‚è´¹å½•å…¥")
    with st.form("misc_form"):
        pj = st.text_input("é¡¹ç›®åç§°")
        cat = st.text_input("æ‚è´¹ç±»ç›®")
        amt = st.number_input("é‡‘é¢", min_value=0.0)
        cur = st.selectbox("å¸ç§", ["IDR","USD","RMB","SGD","MYR","THB"])
        ok = st.form_submit_button("â• æ·»åŠ æ‚è´¹")
    if ok:
        if not pj or not cat:
            st.error("âŒ å¿…å¡«é¡¹ä¸èƒ½ä¸ºç©º")
        else:
            with engine.begin() as conn:
                conn.execute(text("""
                INSERT INTO misc_costs (é¡¹ç›®åç§°,æ‚è´¹ç±»ç›®,é‡‘é¢,å¸ç§,å½•å…¥äºº,åœ°åŒº)
                VALUES (:p,:c,:a,:cur,:u,:r)
                """), {"p": pj,"c": cat,"a": amt,"cur": cur,"u": user["username"],"r": user["region"]})
            st.success("âœ… æ‚è´¹å·²æ·»åŠ ã€‚")

# ============ æŸ¥è¯¢æ¨¡å— ============
elif page == "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢":
    st.header("ğŸ“‹ è®¾å¤‡æŸ¥è¯¢")
    kw = st.text_input("å…³é”®è¯ï¼ˆæŒ‰é€‰å®šå­—æ®µæœç´¢ï¼‰")
    search_fields = st.multiselect("é€‰æ‹©è¦åœ¨å…¶å†…æœç´¢å…³é”®è¯ï¼ˆä¸é€‰åˆ™åœ¨é»˜è®¤å­—æ®µæœç´¢ï¼‰",
                                   ["è®¾å¤‡ææ–™åç§°", "æè¿°", "å“ç‰Œ", "è§„æ ¼æˆ–å‹å·", "é¡¹ç›®åç§°", "ä¾›åº”å•†åç§°", "åœ°åŒº"])
    pj = st.text_input("æŒ‰é¡¹ç›®åç§°è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰")
    sup = st.text_input("æŒ‰ä¾›åº”å•†åç§°è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰")
    brand_f = st.text_input("æŒ‰å“ç‰Œè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰")
    cur = st.selectbox("å¸ç§", ["å…¨éƒ¨","IDR","USD","RMB","SGD","MYR","THB"], index=0)

    regions_options = ["å…¨éƒ¨","Singapore","Malaysia","Thailand","Indonesia","Vietnam","Philippines","Others","All"]
    if user["role"] == "admin":
        region_filter = st.selectbox("æŒ‰åœ°åŒºè¿‡æ»¤ï¼ˆç®¡ç†å‘˜å¯é€‰ï¼‰", regions_options, index=0)
    else:
        st.info(f"ä»…æ˜¾ç¤ºæ‚¨æ‰€åœ¨åœ°åŒºçš„æ•°æ®ï¼š{user['region']}")
        region_filter = user["region"]

    if st.button("ğŸ” æœç´¢è®¾å¤‡"):
        if not (kw or pj or sup or brand_f or (cur != "å…¨éƒ¨") or (user["role"]=="admin" and region_filter and region_filter!="å…¨éƒ¨")):
            st.warning("è¯·è¾“å…¥å…³é”®è¯æˆ–è‡³å°‘ä¸€ä¸ªè¿‡æ»¤æ¡ä»¶ã€‚")
        else:
            cond, params = [], {}
            if pj:
                cond.append("LOWER(é¡¹ç›®åç§°) LIKE :pj")
                params["pj"] = f"%{pj.lower()}%"
            if sup:
                cond.append("LOWER(ä¾›åº”å•†åç§°) LIKE :sup")
                params["sup"] = f"%{sup.lower()}%"
            if brand_f:
                cond.append("LOWER(å“ç‰Œ) LIKE :brand")
                params["brand"] = f"%{brand_f.lower()}%"
            if cur != "å…¨éƒ¨":
                cond.append("å¸ç§=:c")
                params["c"] = cur
            if user["role"] != "admin":
                cond.append("åœ°åŒº=:r")
                params["r"] = user["region"]
            else:
                if region_filter and region_filter != "å…¨éƒ¨":
                    cond.append("åœ°åŒº=:r")
                    params["r"] = region_filter

            if kw:
                tokens = re.findall(r"\S+", kw)
                if search_fields:
                    fields_to_search = search_fields
                else:
                    fields_to_search = ["è®¾å¤‡ææ–™åç§°","æè¿°","å“ç‰Œ","è§„æ ¼æˆ–å‹å·","é¡¹ç›®åç§°","ä¾›åº”å•†åç§°"]
                for i, token in enumerate(tokens):
                    ors = []
                    for j, f in enumerate(fields_to_search):
                        param_name = f"kw_{i}_{j}"
                        ors.append(f"LOWER({f}) LIKE :{param_name}")
                        params[param_name] = f"%{token.lower()}%"
                    cond.append("(" + " OR ".join(ors) + ")")

            sql = "SELECT * FROM quotations"
            if cond:
                sql += " WHERE " + " AND ".join(cond)
            df = pd.read_sql(sql, engine, params=params)
            safe_st_dataframe(df)
            if not df.empty:
                buf = io.BytesIO()
                with pd.ExcelWriter(buf, engine="openpyxl") as w:
                    df.to_excel(w, index=False)
                buf.seek(0)
                st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ", buf, "è®¾å¤‡æŸ¥è¯¢ç»“æœ.xlsx")

elif page == "ğŸ’° æ‚è´¹æŸ¥è¯¢":
    st.header("ğŸ’° æ‚è´¹æŸ¥è¯¢")
    pj2 = st.text_input("æŒ‰é¡¹ç›®åç§°è¿‡æ»¤")
    if st.button("ğŸ” æœç´¢æ‚è´¹"):
        params = {"pj": f"%{pj2.lower()}%"}
        sql = "SELECT * FROM misc_costs WHERE LOWER(é¡¹ç›®åç§°) LIKE :pj"
        if user["role"] != "admin":
            sql += " AND åœ°åŒº=:r"
            params["r"] = user["region"]
        df2 = pd.read_sql(sql, engine, params=params)
        safe_st_dataframe(df2)
        if not df2.empty:
            buf2 = io.BytesIO()
            with pd.ExcelWriter(buf2, engine="openpyxl") as w:
                df2.to_excel(w, index=False)
            buf2.seek(0)
            st.download_button("ğŸ“¥ ä¸‹è½½æ‚è´¹ç»“æœ", buf2, "æ‚è´¹æŸ¥è¯¢ç»“æœ.xlsx")

elif page == "ğŸ‘‘ ç®¡ç†å‘˜åå°" and user["role"] == "admin":
    st.header("ğŸ‘‘ ç®¡ç†å‘˜åå°")
    users_df = pd.read_sql("SELECT username, role, region FROM users", engine)
    safe_st_dataframe(users_df)
