# -*- coding: utf-8 -*-
"""
Complete app_streamlit.py with compatibility-safe rerun and previous fixes integrated.

Changes:
- Added safe_rerun() to replace direct calls to st.experimental_rerun() for compatibility.
- Replaced all st.experimental_rerun() calls with safe_rerun().
- Retained previous robustness fixes:
  - normalize_for_display + safe_st_dataframe to avoid pyarrow ArrowTypeError.
  - Robust mapped_but_empty detection and fill-only-empty global apply.
  - Admin delete verified with SELECT and using result.rowcount.
- Unique widget keys to avoid session_state collisions.

Usage:
- Save as main/app_streamlit.py and run: streamlit run main/app_streamlit.py
- Default admin user: admin / admin123 (example only).
"""
import streamlit as st
import pandas as pd
from sqlalchemy import create_engine, text
import hashlib, io, re
from datetime import date

st.set_page_config(page_title="CMI è¯¢ä»·å½•å…¥ä¸æŸ¥è¯¢å¹³å°", layout="wide")

# --- Compatibility helper: safe_rerun ---
def safe_rerun():
    """
    Attempt to perform a Streamlit rerun in a way that works across versions.
    - Prefer st.experimental_rerun if available.
    - Otherwise, try raising internal RerunException if available.
    - As a last resort set a session flag and show a warning to the user.
    """
    try:
        if hasattr(st, "experimental_rerun"):
            st.experimental_rerun()
            return
        # Try internal exception (different streamlit versions hide this)
        try:
            # This import may fail on some versions
            from streamlit.runtime.scriptrunner import RerunException
            raise RerunException()
        except Exception:
            # Final fallback
            st.session_state["_needs_refresh"] = True
            st.warning("è¯·æ‰‹åŠ¨åˆ·æ–°é¡µé¢ä»¥æŸ¥çœ‹æœ€æ–°çŠ¶æ€ï¼ˆè‡ªåŠ¨åˆ·æ–°åœ¨å½“å‰ Streamlit ç‰ˆæœ¬ä¸å¯ç”¨ï¼‰ã€‚")
            return
    except Exception:
        st.session_state["_needs_refresh"] = True
        st.warning("æ— æ³•è‡ªåŠ¨é‡å¯ï¼Œè¯·æ‰‹åŠ¨åˆ·æ–°æµè§ˆå™¨é¡µé¢ã€‚")
        return

# Database engine (adjust URI in production)
engine = create_engine("sqlite:///quotation.db", connect_args={"check_same_thread": False})

# ============ Initialize DB ============
with engine.begin() as conn:
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT UNIQUE,
        password TEXT,
        role TEXT CHECK(role IN ('admin','user')),
        region TEXT
    )"""))
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS quotations (
        åºå· TEXT,
        è®¾å¤‡ææ–™åç§° TEXT NOT NULL,
        è§„æ ¼æˆ–å‹å· TEXT,
        æè¿° TEXT,
        å“ç‰Œ TEXT NOT NULL,
        å•ä½ TEXT,
        æ•°é‡ç¡®è®¤ REAL,
        æŠ¥ä»·å“ç‰Œ TEXT,
        å‹å· TEXT,
        è®¾å¤‡å•ä»· REAL,
        è®¾å¤‡å°è®¡ REAL,
        äººå·¥åŒ…å¹²å•ä»· REAL,
        äººå·¥åŒ…å¹²å°è®¡ REAL,
        ç»¼åˆå•ä»·æ±‡æ€» REAL,
        å¸ç§ TEXT,
        åŸå‚å“ç‰Œç»´ä¿æœŸé™ TEXT,
        è´§æœŸ TEXT,
        å¤‡æ³¨ TEXT,
        è¯¢ä»·äºº TEXT,
        é¡¹ç›®åç§° TEXT,
        ä¾›åº”å•†åç§° TEXT,
        è¯¢ä»·æ—¥æœŸ TEXT,
        å½•å…¥äºº TEXT,
        åœ°åŒº TEXT
    )"""))
    conn.execute(text("""
    CREATE TABLE IF NOT EXISTS misc_costs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        é¡¹ç›®åç§° TEXT,
        æ‚è´¹ç±»ç›® TEXT,
        é‡‘é¢ REAL,
        å¸ç§ TEXT,
        å½•å…¥äºº TEXT,
        åœ°åŒº TEXT
    )"""))
    # default admin
    conn.execute(text("""
    INSERT OR IGNORE INTO users (username, password, role, region)
    VALUES ('admin', :pw, 'admin', 'All')"""), {"pw": hashlib.sha256("admin123".encode()).hexdigest()})

# ============ Config / Helpers ============
HEADER_SYNONYMS = {
    "åºå·":"åºå·","no":"åºå·","index":"åºå·",
    "è®¾å¤‡ææ–™åç§°":"è®¾å¤‡ææ–™åç§°","è®¾å¤‡åç§°":"è®¾å¤‡ææ–™åç§°","material":"è®¾å¤‡ææ–™åç§°","name":"è®¾å¤‡ææ–™åç§°",
    "è§„æ ¼æˆ–å‹å·":"è§„æ ¼æˆ–å‹å·","è§„æ ¼":"è§„æ ¼æˆ–å‹å·","model":"è§„æ ¼æˆ–å‹å·","spec":"è§„æ ¼æˆ–å‹å·",
    "æè¿°":"æè¿°","description":"æè¿°",
    "å“ç‰Œ":"å“ç‰Œ","brand":"å“ç‰Œ",
    "å•ä½":"å•ä½","unit":"å•ä½",
    "æ•°é‡ç¡®è®¤":"æ•°é‡ç¡®è®¤","æ•°é‡":"æ•°é‡ç¡®è®¤","qty":"æ•°é‡ç¡®è®¤","quantity":"æ•°é‡ç¡®è®¤",
    "æŠ¥ä»·å“ç‰Œ":"æŠ¥ä»·å“ç‰Œ","æŠ¥ä»·":"æŠ¥ä»·å“ç‰Œ",
    "å‹å·":"å‹å·",
    "è®¾å¤‡å•ä»·":"è®¾å¤‡å•ä»·","å•ä»·":"è®¾å¤‡å•ä»·","price":"è®¾å¤‡å•ä»·",
    "è®¾å¤‡å°è®¡":"è®¾å¤‡å°è®¡","subtotal":"è®¾å¤‡å°è®¡",
    "å¸ç§":"å¸ç§","currency":"å¸ç§",
    "è¯¢ä»·äºº":"è¯¢ä»·äºº","é¡¹ç›®åç§°":"é¡¹ç›®åç§°","ä¾›åº”å•†åç§°":"ä¾›åº”å•†åç§°","è¯¢ä»·æ—¥æœŸ":"è¯¢ä»·æ—¥æœŸ","å½•å…¥äºº":"å½•å…¥äºº","åœ°åŒº":"åœ°åŒº"
}
DB_COLUMNS = ["åºå·","è®¾å¤‡ææ–™åç§°","è§„æ ¼æˆ–å‹å·","æè¿°","å“ç‰Œ","å•ä½","æ•°é‡ç¡®è®¤",
              "æŠ¥ä»·å“ç‰Œ","å‹å·","è®¾å¤‡å•ä»·","è®¾å¤‡å°è®¡","äººå·¥åŒ…å¹²å•ä»·","äººå·¥åŒ…å¹²å°è®¡",
              "ç»¼åˆå•ä»·æ±‡æ€»","å¸ç§","åŸå‚å“ç‰Œç»´ä¿æœŸé™","è´§æœŸ","å¤‡æ³¨",
              "è¯¢ä»·äºº","é¡¹ç›®åç§°","ä¾›åº”å•†åç§°","è¯¢ä»·æ—¥æœŸ","å½•å…¥äºº","åœ°åŒº"]

def auto_map_header(orig_header: str):
    if orig_header is None:
        return None
    h = str(orig_header).strip().lower()
    for k, v in HEADER_SYNONYMS.items():
        if h == k.lower():
            return v
    h_norm = re.sub(r"[\s\-\_ï¼š:ï¼ˆï¼‰()]+", " ", h).strip()
    for k, v in HEADER_SYNONYMS.items():
        if h_norm == re.sub(r"[\s\-\_ï¼š:ï¼ˆï¼‰()]+", " ", k.lower()).strip():
            return v
    for k, v in HEADER_SYNONYMS.items():
        if k.lower() in h or h in k.lower():
            return v
    return None

def normalize_for_display(df: pd.DataFrame) -> pd.DataFrame:
    """Normalize DataFrame so Streamlit/pyarrow can serialize it safely."""
    if df is None:
        return df
    df_disp = df.copy()
    for col in df_disp.columns:
        try:
            ser = df_disp[col]
            # If it's DataFrame-like accidentally, coerce to str
            if isinstance(ser, pd.DataFrame):
                df_disp[col] = ser.astype(str).apply(lambda x: x.str.slice(0, 100)).astype(str)
                continue
            # For object dtypes, ensure consistent element types (stringify mixed)
            if ser.dtype == "object":
                non_null = ser.dropna()
                if non_null.empty:
                    df_disp[col] = ser.where(ser.notna(), "").astype(str)
                    continue
                types_seen = {type(x) for x in non_null}
                has_bytes = any(isinstance(x, (bytes, bytearray, memoryview)) for x in non_null)
                multiple_types = len(types_seen) > 1
                if has_bytes or multiple_types:
                    df_disp[col] = ser.where(ser.notna(), None).apply(lambda x: "" if x is None else str(x))
                else:
                    df_disp[col] = ser.where(ser.notna(), None).apply(lambda x: "" if x is None else x)
        except Exception:
            df_disp[col] = df_disp[col].where(df_disp[col].notna(), None).apply(lambda x: "" if x is None else str(x))
    return df_disp

def safe_st_dataframe(df: pd.DataFrame, height: int | None = None):
    df_disp = normalize_for_display(df)
    try:
        if height is None:
            st.dataframe(df_disp)
        else:
            st.dataframe(df_disp, height=height)
    except Exception:
        # Last resort stringify everything
        df2 = df_disp.copy()
        for col in df2.columns:
            df2[col] = df2[col].astype(str).fillna("")
        if height is None:
            st.dataframe(df2)
        else:
            st.dataframe(df2, height=height)

# ============ Auth UI ============
def login_form():
    st.subheader("ğŸ” ç”¨æˆ·ç™»å½•")
    username = st.text_input("ç”¨æˆ·å", key="login_user")
    password = st.text_input("å¯†ç ", type="password", key="login_pass")
    if st.button("ç™»å½•", key="login_button"):
        pw_hash = hashlib.sha256(password.encode()).hexdigest()
        with engine.begin() as conn:
            user = conn.execute(text("SELECT * FROM users WHERE username=:u AND password=:p"), {"u": username, "p": pw_hash}).fetchone()
        if user:
            st.session_state["user"] = {"username": username, "role": user.role, "region": user.region}
            st.success(f"âœ… ç™»å½•æˆåŠŸï¼æ¬¢è¿ {username}ï¼ˆ{user.region}ï¼‰")
            safe_rerun()
        else:
            st.error("âŒ ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

def register_form():
    st.subheader("ğŸ§¾ æ³¨å†Œ")
    ru = st.text_input("æ–°ç”¨æˆ·å", key="reg_user")
    rp = st.text_input("æ–°å¯†ç ", type="password", key="reg_pass")
    region = st.selectbox("åœ°åŒº", ["Singapore","Malaysia","Thailand","Indonesia","Vietnam","Philippines","Others"], key="reg_region")
    if st.button("æ³¨å†Œ", key="reg_button"):
        if not ru or not rp:
            st.warning("ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º")
        else:
            pw_hash = hashlib.sha256(rp.encode()).hexdigest()
            try:
                with engine.begin() as conn:
                    conn.execute(text("INSERT INTO users (username,password,role,region) VALUES (:u,:p,'user',:r)"),
                                 {"u": ru, "p": pw_hash, "r": region})
                st.success("æ³¨å†ŒæˆåŠŸï¼Œè¯·ç™»å½•")
            except Exception:
                st.error("ç”¨æˆ·åå·²å­˜åœ¨")

def logout():
    if "user" in st.session_state:
        del st.session_state["user"]
    safe_rerun()

# ============ Page flow ============
if "user" not in st.session_state:
    tabs = st.tabs(["ğŸ”‘ ç™»å½•","ğŸ§¾ æ³¨å†Œ"])
    with tabs[0]:
        login_form()
    with tabs[1]:
        register_form()
    st.stop()

# If earlier safe_rerun set a refresh flag, show a manual refresh button
if st.session_state.get("_needs_refresh", False):
    if st.button("æ‰‹åŠ¨åˆ·æ–°é¡µé¢", key="manual_refresh"):
        # try best-effort rerun
        safe_rerun()

user = st.session_state["user"]
st.sidebar.markdown(f"ğŸ‘¤ **{user['username']}**  \nğŸ¢ åœ°åŒºï¼š{user['region']}  \nğŸ”‘ è§’è‰²ï¼š{user['role']}")
if st.sidebar.button("é€€å‡ºç™»å½•", key="logout_btn"):
    logout()

page = st.sidebar.radio("å¯¼èˆª", ["ğŸ  ä¸»é¡µé¢", "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢", "ğŸ’° æ‚è´¹æŸ¥è¯¢", "ğŸ‘‘ ç®¡ç†å‘˜åå°"] if user["role"]=="admin" else ["ğŸ  ä¸»é¡µé¢", "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢", "ğŸ’° æ‚è´¹æŸ¥è¯¢"])

# ============ Main: Upload / Mapping / Import ============
if page == "ğŸ  ä¸»é¡µé¢":
    st.title("ğŸ“Š è¯¢ä»·å½•å…¥ä¸æŸ¥è¯¢å¹³å°")
    st.header("ğŸ“‚ Excel æ‰¹é‡å½•å…¥ï¼ˆæ™ºèƒ½è¡¨å¤´æ˜ å°„ï¼‰")

    template = pd.DataFrame(columns=[c for c in DB_COLUMNS if c not in ("å½•å…¥äºº","åœ°åŒº")])
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        template.to_excel(writer, index=False)
    buf.seek(0)
    st.download_button("ä¸‹è½½æ¨¡æ¿", buf, "quotation_template.xlsx", key="download_template")

    uploaded = st.file_uploader("ä¸Šä¼  Excel (.xlsx)", type=["xlsx"], key="upload_excel")
    if uploaded:
        try:
            preview = pd.read_excel(uploaded, header=None, nrows=50, dtype=object)
            safe_st_dataframe(preview.head(10))
        except Exception as e:
            st.error(f"è¯»å–é¢„è§ˆå¤±è´¥ï¼š{e}")
            preview = None

        if preview is not None:
            header_names, header_row_index = detect_header_from_preview(preview, max_header_rows=2, max_search_rows=8)
            raw_df_full = pd.read_excel(uploaded, header=None, dtype=object)
            if header_names is None:
                header_row_index = 0
                header_names = [str(x) if not pd.isna(x) else "" for x in raw_df_full.iloc[0].tolist()]
            data_df = raw_df_full.iloc[header_row_index+1:].copy().reset_index(drop=True)
            if len(header_names) < data_df.shape[1]:
                header_names += [f"Unnamed_{i}" for i in range(len(header_names), data_df.shape[1])]
            data_df.columns = header_names

            st.write("åŸå§‹è¡¨å¤´ï¼š", list(data_df.columns))

            mapping_targets = ["Ignore"] + [c for c in DB_COLUMNS if c not in ("å½•å…¥äºº","åœ°åŒº")]
            auto_defaults = {col: (auto_map_header(col) if auto_map_header(col) in mapping_targets else "Ignore") for col in data_df.columns}

            with st.form("mapping_form_full", clear_on_submit=False):
                cols_l, cols_r = st.columns(2)
                mapped = {}
                for i, col in enumerate(data_df.columns):
                    container = cols_l if i % 2 == 0 else cols_r
                    default = auto_defaults.get(col, "Ignore")
                    sel = container.selectbox(f"{col}", mapping_targets, index=mapping_targets.index(default) if default in mapping_targets else 0, key=f"map_full_{i}")
                    mapped[col] = sel
                submit_map = st.form_submit_button("åº”ç”¨æ˜ å°„å¹¶é¢„è§ˆ")

            if submit_map:
                # Build target_sources: target -> [src1, src2,...]
                target_sources = {}
                for src_col, tgt in mapped.items():
                    if tgt != "Ignore":
                        target_sources.setdefault(tgt, []).append(src_col)

                # Robust mapped_but_empty detection
                mapped_but_empty = []
                for tgt, srcs in target_sources.items():
                    has_value = False
                    # flatten any nested lists defensively
                    src_list = []
                    for item in srcs:
                        if isinstance(item, (list, tuple, set)):
                            src_list.extend(item)
                        else:
                            src_list.append(item)
                    for src_col in src_list:
                        if src_col in data_df.columns:
                            ser = data_df[src_col].astype(object)
                            try:
                                ser_norm = ser.where(~ser.astype(str).str.strip().isin(["", "nan", "none"]), pd.NA)
                            except Exception:
                                ser_norm = ser.apply(lambda x: None if pd.isna(x) else (str(x).strip() if str(x).strip().lower() not in ("", "nan", "none") else pd.NA))
                            if ser_norm.dropna().shape[0] > 0:
                                has_value = True
                                break
                    if not has_value:
                        mapped_but_empty.append(tgt)

                # Build df_for_db
                rename_dict = {k: v for k, v in mapped.items() if v != "Ignore"}
                df_mapped = data_df.rename(columns=rename_dict)
                for c in DB_COLUMNS:
                    if c not in df_mapped.columns:
                        df_mapped[c] = pd.NA
                df_mapped["å½•å…¥äºº"] = user["username"]
                df_mapped["åœ°åŒº"] = user["region"]
                df_for_db = df_mapped[DB_COLUMNS]

                # Save mapping CSV to session
                csv_buf = io.StringIO()
                df_for_db.to_csv(csv_buf, index=False)
                st.session_state["mapping_csv"] = csv_buf.getvalue()
                st.session_state["mapping_done"] = True
                st.session_state["mapping_target_sources"] = target_sources
                st.session_state["mapping_mapped_but_empty"] = mapped_but_empty

                st.success("æ˜ å°„ä¿å­˜ã€‚è¯·å¡«å†™å…¨å±€ä¿¡æ¯ï¼ˆè‹¥å¿…è¦ï¼‰å¹¶åº”ç”¨ä»¥ç»§ç»­å¯¼å…¥ã€‚")
                if mapped_but_empty:
                    st.warning(f"æ³¨æ„ï¼šä»¥ä¸‹ç›®æ ‡åˆ—ä»æºæ•°æ®æœªæ£€æµ‹åˆ°æœ‰æ•ˆå€¼ï¼š{', '.join(mapped_but_empty)}")

    # Manual entry form
    st.header("âœï¸ æ‰‹å·¥å½•å…¥è®¾å¤‡")
    with st.form("manual_add_form", clear_on_submit=True):
        col1, col2, col3 = st.columns(3)
        pj = col1.text_input("é¡¹ç›®åç§°", key="manual_pj")
        sup = col2.text_input("ä¾›åº”å•†åç§°", key="manual_sup")
        inq = col3.text_input("è¯¢ä»·äºº", key="manual_inq")
        name = st.text_input("è®¾å¤‡ææ–™åç§°", key="manual_name")
        brand = st.text_input("å“ç‰Œ", key="manual_brand")
        qty = st.number_input("æ•°é‡ç¡®è®¤", min_value=0.0, key="manual_qty")
        price = st.number_input("è®¾å¤‡å•ä»·", min_value=0.0, key="manual_price")
        cur = st.selectbox("å¸ç§", ["IDR","USD","RMB","SGD","MYR","THB"], key="manual_cur")
        desc = st.text_area("æè¿°", key="manual_desc")
        date_inq = st.date_input("è¯¢ä»·æ—¥æœŸ", key="manual_date")
        submit_manual = st.form_submit_button("æ·»åŠ è®°å½•")
    if submit_manual:
        if not (pj and sup and inq and name and brand):
            st.error("å¿…å¡«é¡¹ä¸èƒ½ä¸ºç©º")
        else:
            with engine.begin() as conn:
                conn.execute(text("""
                    INSERT INTO quotations (é¡¹ç›®åç§°,ä¾›åº”å•†åç§°,è¯¢ä»·äºº,è®¾å¤‡ææ–™åç§°,å“ç‰Œ,æ•°é‡ç¡®è®¤,è®¾å¤‡å•ä»·,å¸ç§,æè¿°,å½•å…¥äºº,åœ°åŒº,è¯¢ä»·æ—¥æœŸ)
                    VALUES (:p,:s,:i,:n,:b,:q,:pr,:c,:d,:u,:reg,:dt)
                """), {"p": pj, "s": sup, "i": inq, "n": name, "b": brand, "q": qty, "pr": price,
                       "c": cur, "d": desc, "u": user["username"], "reg": user["region"], "dt": str(date_inq)})
            st.success("æ‰‹å·¥è®°å½•å·²æ·»åŠ ")

    # Apply global values and import if mapping exists in session
    if st.session_state.get("mapping_done", False) and st.session_state.get("mapping_csv", None):
        st.markdown("---")
        st.markdown("è¯·å¡«å†™å…¨å±€ä¿¡æ¯ï¼ˆä¼šå¡«å……åˆ°æ˜ å°„è¡¨ä¸­çš„ç¼ºå¤±é¡¹ï¼Œä»…å¡«ç©ºå¤„ï¼‰ï¼š")
        # load df_for_db
        csv_buf = io.StringIO(st.session_state["mapping_csv"])
        df_for_db = pd.read_csv(csv_buf, dtype=object)
        for c in DB_COLUMNS:
            if c not in df_for_db.columns:
                df_for_db[c] = pd.NA
        df_for_db = df_for_db[DB_COLUMNS]

        # show preview safely
        st.markdown("æ˜ å°„åé¢„è§ˆï¼ˆå‰10è¡Œï¼‰ï¼š")
        safe_st_dataframe(df_for_db.head(10))

        with st.form("global_form_apply", clear_on_submit=False):
            col_a, col_b, col_c, col_d, col_e = st.columns(5)
            global_project = col_a.text_input("é¡¹ç›®åç§°", value=st.session_state.get("global_project", ""), key="global_project")
            global_supplier = col_b.text_input("ä¾›åº”å•†åç§°", value=st.session_state.get("global_supplier", ""), key="global_supplier")
            global_enquirer = col_c.text_input("è¯¢ä»·äºº", value=st.session_state.get("global_enquirer", ""), key="global_enquirer")
            default_date = st.session_state.get("global_date", "")
            try:
                if default_date:
                    global_date = col_d.date_input("è¯¢ä»·æ—¥æœŸ", value=pd.to_datetime(default_date).date(), key="global_date")
                else:
                    global_date = col_d.date_input("è¯¢ä»·æ—¥æœŸ", value=date.today(), key="global_date")
            except Exception:
                global_date = col_d.date_input("è¯¢ä»·æ—¥æœŸ", value=date.today(), key="global_date")
            global_currency = col_e.selectbox("å¸ç§ï¼ˆç”¨äºå¡«å……ç©ºå€¼ï¼‰", ["","IDR","USD","RMB","SGD","MYR","THB"], index=0, key="global_currency")
            apply_global = st.form_submit_button("åº”ç”¨å…¨å±€å¹¶ç»§ç»­å¯¼å…¥")
        if apply_global:
            # basic required checks
            if not (global_project and global_supplier and global_enquirer and global_date):
                st.error("å¿…é¡»å¡«å†™ï¼šé¡¹ç›®åç§°ã€ä¾›åº”å•†åç§°ã€è¯¢ä»·äººå’Œè¯¢ä»·æ—¥æœŸ")
            else:
                # fill only empty values (do not overwrite existing)
                df_final = df_for_db.copy()
                df_final["é¡¹ç›®åç§°"] = df_final["é¡¹ç›®åç§°"].fillna("").astype(str)
                mask_proj = df_final["é¡¹ç›®åç§°"].astype(str).str.strip() == ""
                df_final.loc[mask_proj, "é¡¹ç›®åç§°"] = str(global_project)

                df_final["ä¾›åº”å•†åç§°"] = df_final["ä¾›åº”å•†åç§°"].fillna("").astype(str)
                mask_sup = df_final["ä¾›åº”å•†åç§°"].astype(str).str.strip() == ""
                df_final.loc[mask_sup, "ä¾›åº”å•†åç§°"] = str(global_supplier)

                df_final["è¯¢ä»·äºº"] = df_final["è¯¢ä»·äºº"].fillna("").astype(str)
                mask_inq = df_final["è¯¢ä»·äºº"].astype(str).str.strip() == ""
                df_final.loc[mask_inq, "è¯¢ä»·äºº"] = str(global_enquirer)

                df_final["è¯¢ä»·æ—¥æœŸ"] = df_final["è¯¢ä»·æ—¥æœŸ"].fillna("").astype(str)
                mask_date = df_final["è¯¢ä»·æ—¥æœŸ"].astype(str).str.strip() == ""
                df_final.loc[mask_date, "è¯¢ä»·æ—¥æœŸ"] = str(global_date)

                if global_currency:
                    df_final["å¸ç§"] = df_final["å¸ç§"].fillna("").astype(str)
                    mask_cur = df_final["å¸ç§"].astype(str).str.strip() == ""
                    df_final.loc[mask_cur, "å¸ç§"] = str(global_currency)

                # Normalize empties and check overall required
                def normalize_cell(x):
                    if pd.isna(x):
                        return None
                    s = str(x).strip()
                    if s.lower() in ("", "nan", "none"):
                        return None
                    return s

                overall_required = ["é¡¹ç›®åç§°","ä¾›åº”å•†åç§°","è¯¢ä»·äºº","è®¾å¤‡ææ–™åç§°","å“ç‰Œ","è®¾å¤‡å•ä»·","å¸ç§","è¯¢ä»·æ—¥æœŸ"]
                check_df = df_final[overall_required].applymap(normalize_cell)
                rows_missing_mask = check_df.isna().any(axis=1)

                df_valid = df_final[~rows_missing_mask].copy()
                df_invalid = df_final[rows_missing_mask].copy()

                imported_count = 0
                if not df_valid.empty:
                    try:
                        df_to_store = df_valid.dropna(how="all").drop_duplicates().reset_index(drop=True)
                        # final insert
                        with engine.begin() as conn:
                            df_to_store.to_sql("quotations", conn, if_exists="append", index=False)
                        imported_count = len(df_to_store)
                        st.success(f"å·²å¯¼å…¥ {imported_count} æ¡è®°å½•")
                    except Exception as e:
                        st.error(f"å¯¼å…¥å¼‚å¸¸ï¼š{e}")
                else:
                    st.info("æ²¡æœ‰æ»¡è¶³å¿…å¡«æ¡ä»¶çš„è®°å½•å¯å¯¼å…¥")

                if not df_invalid.empty:
                    st.warning(f"{len(df_invalid)} æ¡è®°å½•ç¼ºå°‘å¿…å¡«å­—æ®µï¼Œå·²æ˜¾ç¤ºä¾›æ‚¨ä¸‹è½½ä¿®æ­£")
                    safe_st_dataframe(df_invalid.head(50))
                    buf_bad = io.BytesIO()
                    with pd.ExcelWriter(buf_bad, engine="openpyxl") as w:
                        df_invalid.to_excel(w, index=False)
                    buf_bad.seek(0)
                    st.download_button("ä¸‹è½½æœªé€šè¿‡è®°å½•", buf_bad, "invalid_rows.xlsx", key="download_invalid")
                # clear mapping session to avoid reapply accidentally
                if imported_count > 0:
                    st.session_state.pop("mapping_csv", None)
                    st.session_state.pop("mapping_done", None)
                    st.session_state.pop("mapping_target_sources", None)
                    st.session_state.pop("mapping_mapped_but_empty", None)

# ============ Search / Delete (Admin) ============
if page == "ğŸ“‹ è®¾å¤‡æŸ¥è¯¢":
    st.header("ğŸ“‹ è®¾å¤‡æŸ¥è¯¢")
    kw = st.text_input("å…³é”®è¯ï¼ˆå¤šä¸ªç©ºæ ¼åˆ†è¯ï¼‰", key="search_kw")
    search_fields = st.multiselect("æœç´¢å­—æ®µï¼ˆç•™ç©ºä¸ºé»˜è®¤ï¼‰",
                                   ["è®¾å¤‡ææ–™åç§°", "æè¿°", "å“ç‰Œ", "è§„æ ¼æˆ–å‹å·", "é¡¹ç›®åç§°", "ä¾›åº”å•†åç§°", "åœ°åŒº"],
                                   key="search_fields")
    pj_filter = st.text_input("æŒ‰é¡¹ç›®åç§°è¿‡æ»¤", key="search_pj")
    sup_filter = st.text_input("æŒ‰ä¾›åº”å•†åç§°è¿‡æ»¤", key="search_sup")
    brand_filter = st.text_input("æŒ‰å“ç‰Œè¿‡æ»¤", key="search_brand")
    cur_filter = st.selectbox("å¸ç§", ["å…¨éƒ¨","IDR","USD","RMB","SGD","MYR","THB"], index=0, key="search_cur")

    regions_options = ["å…¨éƒ¨","Singapore","Malaysia","Thailand","Indonesia","Vietnam","Philippines","Others","All"]
    if user["role"] == "admin":
        region_filter = st.selectbox("æŒ‰åœ°åŒºè¿‡æ»¤ï¼ˆç®¡ç†å‘˜ï¼‰", regions_options, index=0, key="search_region")
    else:
        st.info(f"ä»…æ˜¾ç¤ºæ‚¨æ‰€åœ¨åœ°åŒºçš„æ•°æ®ï¼š{user['region']}")
        region_filter = user["region"]

    if st.button("ğŸ” æœç´¢è®¾å¤‡", key="search_button"):
        conds = []
        params = {}
        if pj_filter:
            conds.append("LOWER(é¡¹ç›®åç§°) LIKE :pj")
            params["pj"] = f"%{pj_filter.lower()}%"
        if sup_filter:
            conds.append("LOWER(ä¾›åº”å•†åç§°) LIKE :sup")
            params["sup"] = f"%{sup_filter.lower()}%"
        if brand_filter:
            conds.append("LOWER(å“ç‰Œ) LIKE :brand")
            params["brand"] = f"%{brand_filter.lower()}%"
        if cur_filter != "å…¨éƒ¨":
            conds.append("å¸ç§ = :cur")
            params["cur"] = cur_filter
        if user["role"] != "admin":
            conds.append("åœ°åŒº = :r")
            params["r"] = user["region"]
        else:
            if region_filter and region_filter != "å…¨éƒ¨":
                conds.append("åœ°åŒº = :r")
                params["r"] = region_filter

        if kw:
            tokens = re.findall(r"\S+", kw)
            fields = search_fields if search_fields else ["è®¾å¤‡ææ–™åç§°","æè¿°","å“ç‰Œ","è§„æ ¼æˆ–å‹å·","é¡¹ç›®åç§°","ä¾›åº”å•†åç§°"]
            for i, t in enumerate(tokens):
                ors = []
                for j, f in enumerate(fields):
                    pname = f"kw_{i}_{j}"
                    ors.append(f"LOWER({f}) LIKE :{pname}")
                    params[pname] = f"%{t.lower()}%"
                conds.append("(" + " OR ".join(ors) + ")")

        sql = "SELECT rowid, * FROM quotations"
        if conds:
            sql += " WHERE " + " AND ".join(conds)

        try:
            df = pd.read_sql(sql, engine, params=params)
        except Exception as e:
            st.error(f"æŸ¥è¯¢å¤±è´¥ï¼š{e}")
            df = pd.DataFrame()

        if df.empty:
            st.info("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®°å½•ã€‚")
        else:
            safe_st_dataframe(df)
            # download
            buf = io.BytesIO()
            with pd.ExcelWriter(buf, engine="openpyxl") as writer:
                df.to_excel(writer, index=False)
            buf.seek(0)
            st.download_button("ä¸‹è½½ç»“æœ", buf, "è®¾å¤‡æŸ¥è¯¢ç»“æœ.xlsx", key="download_search")

            # Admin delete form (single form)
            if user["role"] == "admin":
                st.markdown("---")
                st.markdown("âš ï¸ ç®¡ç†å‘˜åˆ é™¤ï¼šé€‰æ‹©è®°å½•å¹¶ç¡®è®¤ã€‚")
                choices = []
                for _, row in df.iterrows():
                    rid = int(row["rowid"])
                    proj = str(row.get("é¡¹ç›®åç§°",""))[:40]
                    name = str(row.get("è®¾å¤‡ææ–™åç§°",""))[:60]
                    brand = str(row.get("å“ç‰Œ",""))[:30]
                    choices.append(f"{rid} | {proj} | {name} | {brand}")

                with st.form("admin_delete_form_final_v2", clear_on_submit=False):
                    selected = st.multiselect("é€‰ä¸­è¦åˆ é™¤çš„è®°å½•", choices, key="admin_delete_selected_v2")
                    confirm = st.checkbox("æˆ‘ç¡®è®¤åˆ é™¤æ‰€é€‰è®°å½•ï¼ˆä¸å¯æ¢å¤ï¼‰", key="admin_delete_confirm_v2")
                    submit_del = st.form_submit_button("åˆ é™¤æ‰€é€‰è®°å½•ï¼ˆç®¡ç†å‘˜ï¼‰", key="admin_delete_submit_v2")

                if submit_del:
                    if not selected:
                        st.warning("è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„è®°å½•ã€‚")
                    elif not confirm:
                        st.warning("è¯·å‹¾é€‰ç¡®è®¤æ¡†ä»¥æ‰§è¡Œåˆ é™¤ã€‚")
                    else:
                        try:
                            selected_rowids = [int(s.split("|",1)[0].strip()) for s in selected]
                        except Exception as e:
                            st.error(f"è§£ææ‰€é€‰ rowid å¤±è´¥ï¼š{e}")
                            selected_rowids = []

                        if not selected_rowids:
                            st.warning("æ— æœ‰æ•ˆ rowidï¼Œå–æ¶ˆåˆ é™¤ã€‚")
                        else:
                            placeholders = ",".join(str(int(r)) for r in selected_rowids)
                            select_verify_sql = f"SELECT rowid, é¡¹ç›®åç§°, ä¾›åº”å•†åç§°, è®¾å¤‡ææ–™åç§°, å“ç‰Œ FROM quotations WHERE rowid IN ({placeholders})"
                            try:
                                matched_df = pd.read_sql(select_verify_sql, engine)
                            except Exception as e:
                                st.error(f"åŒ¹é…æŸ¥è¯¢å¤±è´¥ï¼š{e}")
                                matched_df = pd.DataFrame()

                            if matched_df.empty:
                                st.warning("æœªåœ¨æ•°æ®åº“ä¸­åŒ¹é…åˆ°æ‰€é€‰ rowidï¼Œå–æ¶ˆåˆ é™¤ã€‚")
                                st.write("æ‰§è¡Œçš„ SELECT SQLï¼š", select_verify_sql)
                            else:
                                st.markdown("ä»¥ä¸‹ä¸ºå°†è¢«åˆ é™¤çš„åŒ¹é…è®°å½•ï¼Œè¯·æ ¸å¯¹ï¼š")
                                safe_st_dataframe(matched_df)

                                # Try archive first (ignore archive errors)
                                try:
                                    with engine.begin() as conn:
                                        conn.execute(text(f"""
                                            INSERT INTO deleted_quotations
                                            SELECT rowid AS original_rowid, åºå·, è®¾å¤‡ææ–™åç§°, è§„æ ¼æˆ–å‹å·, æè¿°, å“ç‰Œ, å•ä½, æ•°é‡ç¡®è®¤,
                                                   æŠ¥ä»·å“ç‰Œ, å‹å·, è®¾å¤‡å•ä»·, è®¾å¤‡å°è®¡, äººå·¥åŒ…å¹²å•ä»·, äººå·¥åŒ…å¹²å°è®¡, ç»¼åˆå•ä»·æ±‡æ€»,
                                                   å¸ç§, åŸå‚å“ç‰Œç»´ä¿æœŸé™, è´§æœŸ, å¤‡æ³¨, è¯¢ä»·äºº, é¡¹ç›®åç§°, ä¾›åº”å•†åç§°, è¯¢ä»·æ—¥æœŸ, å½•å…¥äºº, åœ°åŒº,
                                                   CURRENT_TIMESTAMP AS deleted_at, :user AS deleted_by
                                            FROM quotations WHERE rowid IN ({placeholders})
                                        """), {"user": user["username"]})
                                    st.write("å·²å°è¯•å½’æ¡£ï¼ˆè‹¥è¡¨ä¸å­˜åœ¨åˆ™å¿½ç•¥ï¼‰ã€‚")
                                except Exception as e_arch:
                                    st.warning(f"å½’æ¡£å¼‚å¸¸ï¼ˆå·²å¿½ç•¥ï¼‰ï¼š{e_arch}")

                                # Execute DELETE and check rowcount
                                delete_sql = f"DELETE FROM quotations WHERE rowid IN ({placeholders})"
                                try:
                                    with engine.begin() as conn:
                                        res = conn.execute(text(delete_sql))
                                        deleted_count = getattr(res, "rowcount", None)
                                    if deleted_count is None:
                                        st.info("åˆ é™¤æ‰§è¡Œï¼Œä½†æœªè·å– rowcountï¼Œè¯·æŸ¥è¯¢ç¡®è®¤ã€‚")
                                    elif deleted_count == 0:
                                        st.warning("DELETE æ‰§è¡ŒæˆåŠŸä½†æœªåˆ é™¤ä»»ä½•è¡Œï¼ˆrowcount=0ï¼‰ã€‚")
                                    else:
                                        st.success(f"å·²åˆ é™¤ {deleted_count} æ¡è®°å½•ã€‚")
                                except Exception as e_del:
                                    st.error(f"æ‰§è¡Œ DELETE æ—¶å¼‚å¸¸ï¼š{e_del}")

                                # Verify after deletion
                                try:
                                    after_df = pd.read_sql(select_verify_sql, engine)
                                    if after_df.empty:
                                        st.info("åˆ é™¤åå¤æŸ¥æœªæ‰¾åˆ°è¿™äº›è®°å½•ï¼ˆåˆ é™¤æˆåŠŸï¼‰ã€‚")
                                    else:
                                        st.warning("åˆ é™¤åä»æŸ¥è¯¢åˆ°éƒ¨åˆ†è®°å½•ï¼ˆè¯·æ£€æŸ¥ï¼‰ï¼š")
                                        safe_st_dataframe(after_df)
                                except Exception as e_after:
                                    st.warning(f"åˆ é™¤åå¤æ ¸å¤±è´¥ï¼š{e_after}")

                                safe_rerun()
            else:
                st.info("ä»…ç®¡ç†å‘˜å¯åˆ é™¤è®°å½•ã€‚")

# ============ Misc costs page ============
elif page == "ğŸ’° æ‚è´¹æŸ¥è¯¢":
    st.header("ğŸ’° æ‚è´¹æŸ¥è¯¢")
    pj2 = st.text_input("æŒ‰é¡¹ç›®åç§°è¿‡æ»¤", key="misc_pj")
    if st.button("ğŸ” æœç´¢æ‚è´¹", key="misc_search"):
        params = {"pj": f"%{pj2.lower()}%"}
        sql = "SELECT * FROM misc_costs WHERE LOWER(é¡¹ç›®åç§°) LIKE :pj"
        if user["role"] != "admin":
            sql += " AND åœ°åŒº = :r"
            params["r"] = user["region"]
        df2 = pd.read_sql(sql, engine, params=params)
        safe_st_dataframe(df2)
        if not df2.empty:
            buf2 = io.BytesIO()
            with pd.ExcelWriter(buf2, engine="openpyxl") as writer:
                df2.to_excel(writer, index=False)
            buf2.seek(0)
            st.download_button("ä¸‹è½½æ‚è´¹ç»“æœ", buf2, "misc_costs.xlsx", key="download_misc")

# ============ Admin page ============
elif page == "ğŸ‘‘ ç®¡ç†å‘˜åå°" and user["role"] == "admin":
    st.header("ğŸ‘‘ ç®¡ç†åå°")
    users_df = pd.read_sql("SELECT username, role, region FROM users", engine)
    safe_st_dataframe(users_df)
